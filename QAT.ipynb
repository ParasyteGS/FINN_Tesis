{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32dfdc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Simple_CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Simple_CustomCNN, self).__init__()\n",
    "\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 100)  # Ajusta según el tamaño de entrada\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(100, 2)  # 2 clases: ave y no ave\n",
    "\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.quant(x)\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        x = self.dequant(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "net = Simple_CustomCNN().to(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f6d6023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\AppData\\Local\\Temp\\ipykernel_22964\\4228634201.py:3: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  net_quant = torch.ao.quantization.prepare_qat(net)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Simple_CustomCNN(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (conv1): Conv2d(\n",
       "    3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(\n",
       "    32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(\n",
       "    64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv2d(\n",
       "    128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(\n",
       "    in_features=2048, out_features=100, bias=True\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(\n",
       "    in_features=100, out_features=2, bias=True\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.qconfig = torch.ao.quantization.default_qconfig\n",
    "net.train()\n",
    "net_quant = torch.ao.quantization.prepare_qat(net)\n",
    "net_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b741f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transformaciones: ajustar tamaño y normalizar\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.3, saturation=0.3),\n",
    "        transforms.RandomResizedCrop(64, scale=(0.8, 1.0)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ]\n",
    ")\n",
    "val_dataset = ImageFolder(root=\"dataset_split/val\", transform=val_transform)\n",
    "\n",
    "\n",
    "train_dataset = ImageFolder(root=\"dataset_split/train\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "413dfae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "\n",
    "def train(num_epochs, model):\n",
    "    criterion = nn.CrossEntropyLoss()  # Para clasificación multiclase\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"max\", factor=0.5, patience=3\n",
    "    )\n",
    "    for epoch in range(num_epochs):\n",
    "        # --- Entrenamiento ---\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        train_acc = 100 * correct / total\n",
    "\n",
    "        # --- Validación ---\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "            f\"Loss: {running_loss/len(train_loader):.4f} - \"\n",
    "            f\"Train Acc: {train_acc:.2f}% - \"\n",
    "            f\"Val Acc: {val_acc:.2f}%\"\n",
    "        )\n",
    "\n",
    "        scheduler.step(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c007a1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Loss: 0.6681 - Train Acc: 59.25% - Val Acc: 68.16%\n",
      "Epoch 2/30 - Loss: 0.6655 - Train Acc: 60.50% - Val Acc: 71.14%\n",
      "Epoch 3/30 - Loss: 0.6320 - Train Acc: 66.12% - Val Acc: 74.63%\n",
      "Epoch 4/30 - Loss: 0.6028 - Train Acc: 67.00% - Val Acc: 76.62%\n",
      "Epoch 5/30 - Loss: 0.5982 - Train Acc: 66.38% - Val Acc: 78.61%\n",
      "Epoch 6/30 - Loss: 0.5747 - Train Acc: 70.12% - Val Acc: 81.59%\n",
      "Epoch 7/30 - Loss: 0.5335 - Train Acc: 73.75% - Val Acc: 75.12%\n",
      "Epoch 8/30 - Loss: 0.5374 - Train Acc: 74.75% - Val Acc: 76.12%\n",
      "Epoch 9/30 - Loss: 0.5336 - Train Acc: 73.88% - Val Acc: 82.09%\n",
      "Epoch 10/30 - Loss: 0.5051 - Train Acc: 76.88% - Val Acc: 80.10%\n",
      "Epoch 11/30 - Loss: 0.4995 - Train Acc: 76.38% - Val Acc: 83.08%\n",
      "Epoch 12/30 - Loss: 0.5122 - Train Acc: 76.12% - Val Acc: 83.08%\n",
      "Epoch 13/30 - Loss: 0.4999 - Train Acc: 76.50% - Val Acc: 78.11%\n",
      "Epoch 14/30 - Loss: 0.5128 - Train Acc: 74.62% - Val Acc: 78.11%\n",
      "Epoch 15/30 - Loss: 0.4453 - Train Acc: 80.75% - Val Acc: 78.61%\n",
      "Epoch 16/30 - Loss: 0.4386 - Train Acc: 80.75% - Val Acc: 78.61%\n",
      "Epoch 17/30 - Loss: 0.4050 - Train Acc: 83.25% - Val Acc: 79.10%\n",
      "Epoch 18/30 - Loss: 0.4179 - Train Acc: 81.38% - Val Acc: 78.11%\n",
      "Epoch 19/30 - Loss: 0.4246 - Train Acc: 82.25% - Val Acc: 78.11%\n",
      "Epoch 20/30 - Loss: 0.4138 - Train Acc: 81.38% - Val Acc: 77.11%\n",
      "Epoch 21/30 - Loss: 0.3957 - Train Acc: 80.38% - Val Acc: 77.61%\n",
      "Epoch 22/30 - Loss: 0.4058 - Train Acc: 82.38% - Val Acc: 79.10%\n",
      "Epoch 23/30 - Loss: 0.4033 - Train Acc: 81.75% - Val Acc: 78.11%\n",
      "Epoch 24/30 - Loss: 0.3929 - Train Acc: 82.25% - Val Acc: 77.61%\n",
      "Epoch 25/30 - Loss: 0.3721 - Train Acc: 83.50% - Val Acc: 78.11%\n",
      "Epoch 26/30 - Loss: 0.3945 - Train Acc: 81.62% - Val Acc: 77.61%\n",
      "Epoch 27/30 - Loss: 0.3705 - Train Acc: 83.38% - Val Acc: 77.11%\n",
      "Epoch 28/30 - Loss: 0.3826 - Train Acc: 82.00% - Val Acc: 77.11%\n",
      "Epoch 29/30 - Loss: 0.3743 - Train Acc: 84.38% - Val Acc: 77.61%\n",
      "Epoch 30/30 - Loss: 0.3838 - Train Acc: 82.50% - Val Acc: 76.12%\n"
     ]
    }
   ],
   "source": [
    "train(num_epochs,net_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72c12165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "\n",
    "def test(model, folder=\"Images_test\"):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for class_name in os.listdir(folder):\n",
    "            class_folder = os.path.join(folder, class_name)\n",
    "            if not os.path.isdir(class_folder):\n",
    "                continue\n",
    "\n",
    "            for filename in os.listdir(class_folder):\n",
    "                if filename.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "                    img_path = os.path.join(class_folder, filename)\n",
    "                    img = Image.open(img_path)\n",
    "                    img = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "                    output = model(img)\n",
    "                    pred_class = output.argmax(dim=1).item()\n",
    "\n",
    "                    # Obtenemos el índice de la clase real según train_dataset.classes\n",
    "                    true_class = train_dataset.classes.index(class_name)\n",
    "\n",
    "                    if pred_class == true_class:\n",
    "                        correct += 1\n",
    "                    total += 1\n",
    "\n",
    "    accuracy = 100 * correct / total if total > 0 else 0\n",
    "    print(f\"Precisión total: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56a63c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Simple_CustomCNN(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=-1.0, max_val=1.0)\n",
       "  )\n",
       "  (conv1): Conv2d(\n",
       "    3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=-0.2487485557794571, max_val=0.2315288484096527)\n",
       "    (activation_post_process): MinMaxObserver(min_val=-1.8321338891983032, max_val=1.8092478513717651)\n",
       "  )\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(\n",
       "    32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=-0.14295434951782227, max_val=0.14749263226985931)\n",
       "    (activation_post_process): MinMaxObserver(min_val=-2.678623676300049, max_val=2.7000174522399902)\n",
       "  )\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(\n",
       "    64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=-0.16141840815544128, max_val=0.1687101125717163)\n",
       "    (activation_post_process): MinMaxObserver(min_val=-4.83008337020874, max_val=5.321064472198486)\n",
       "  )\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv2d(\n",
       "    128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=-0.13741609454154968, max_val=0.1965622454881668)\n",
       "    (activation_post_process): MinMaxObserver(min_val=-12.287224769592285, max_val=7.74473762512207)\n",
       "  )\n",
       "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(\n",
       "    in_features=2048, out_features=100, bias=True\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=-0.12249939143657684, max_val=0.13099752366542816)\n",
       "    (activation_post_process): MinMaxObserver(min_val=-11.124725341796875, max_val=10.459854125976562)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(\n",
       "    in_features=100, out_features=2, bias=True\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=-0.11060406267642975, max_val=0.12252682447433472)\n",
       "    (activation_post_process): MinMaxObserver(min_val=-6.718371391296387, max_val=7.493275165557861)\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06aabd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\AppData\\Local\\Temp\\ipykernel_22964\\2840976697.py:2: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  net_quant = torch.ao.quantization.convert(net_quant)\n"
     ]
    }
   ],
   "source": [
    "net_quant.eval()\n",
    "net_quant = torch.ao.quantization.convert(net_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44a77f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check statistics of the various layers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Simple_CustomCNN(\n",
       "  (quant): Quantize(scale=tensor([0.0157]), zero_point=tensor([64]), dtype=torch.quint8)\n",
       "  (conv1): QuantizedConv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.028672296553850174, zero_point=64, padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): QuantizedConv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.042351506650447845, zero_point=63, padding=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.07993029803037643, zero_point=60, padding=(1, 1))\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.15773199498653412, zero_point=78, padding=(1, 1))\n",
       "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): QuantizedLinear(in_features=2048, out_features=100, scale=0.16995732486248016, zero_point=65, qscheme=torch.per_tensor_affine)\n",
       "  (dropout): QuantizedDropout(p=0.5, inplace=False)\n",
       "  (fc2): QuantizedLinear(in_features=100, out_features=2, scale=0.11190273612737656, zero_point=60, qscheme=torch.per_tensor_affine)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Check statistics of the various layers\")\n",
    "net_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "075caf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights before quantization\n",
      "tensor([[[[ -13,   53,  -56],\n",
      "          [ -81,   17,   29],\n",
      "          [ -64,   99,   50]],\n",
      "\n",
      "         [[  44,   11,  -70],\n",
      "          [   2,  -48,   14],\n",
      "          [ -23,  -42,  -45]],\n",
      "\n",
      "         [[  19,   78,    0],\n",
      "          [  18,  -84,   31],\n",
      "          [  52,  -61,   40]]],\n",
      "\n",
      "\n",
      "        [[[  45,  -34,   38],\n",
      "          [ -29,  -16,   22],\n",
      "          [ -53,  -53,   31]],\n",
      "\n",
      "         [[  55,  -78,   90],\n",
      "          [ -84,  106,  -89],\n",
      "          [  80,   14,  -46]],\n",
      "\n",
      "         [[ -61,   26,  -19],\n",
      "          [ -43,  -37,   65],\n",
      "          [  24,   86,  -45]]],\n",
      "\n",
      "\n",
      "        [[[  79,   60,  -36],\n",
      "          [  75,  -21,   74],\n",
      "          [  77,  -12,   44]],\n",
      "\n",
      "         [[ -93,  -32,  -69],\n",
      "          [  13,   -7,  -82],\n",
      "          [ -81,  -93,  -93]],\n",
      "\n",
      "         [[  30,   41,   -4],\n",
      "          [  62,    1,  -62],\n",
      "          [  73,   -7,   35]]],\n",
      "\n",
      "\n",
      "        [[[  68,   24,   14],\n",
      "          [  55,  -67,  -86],\n",
      "          [ -48,  -86,   49]],\n",
      "\n",
      "         [[  85,   93,   61],\n",
      "          [ -54,   -6,   50],\n",
      "          [ -54,   69,    0]],\n",
      "\n",
      "         [[ -81,   33,  -47],\n",
      "          [  95,   54,  -47],\n",
      "          [  87,   77,  -16]]],\n",
      "\n",
      "\n",
      "        [[[ -95,  -14,   56],\n",
      "          [-106,   51,  -78],\n",
      "          [ -21,   -1,  -52]],\n",
      "\n",
      "         [[  -5,    4,  -28],\n",
      "          [  49,   38,  -61],\n",
      "          [  48,  -61,   30]],\n",
      "\n",
      "         [[  86,  -44,  -53],\n",
      "          [ -42,  -23,  -28],\n",
      "          [  31,   64,  101]]],\n",
      "\n",
      "\n",
      "        [[[  36,  -81,  -49],\n",
      "          [  34,   77,   56],\n",
      "          [  40,   82,   36]],\n",
      "\n",
      "         [[  80,   38,   71],\n",
      "          [-101,   17,  -92],\n",
      "          [ -36,   15, -102]],\n",
      "\n",
      "         [[  20,  -99,   52],\n",
      "          [ -28,    9,   80],\n",
      "          [  83,   16,  -55]]],\n",
      "\n",
      "\n",
      "        [[[  61,  -57,  -59],\n",
      "          [ 112,  -51,  -68],\n",
      "          [ -46,   82,   58]],\n",
      "\n",
      "         [[  19,   80,  -26],\n",
      "          [ -62,  -46,  -38],\n",
      "          [  31,   14,  -46]],\n",
      "\n",
      "         [[ -81,  -63,   70],\n",
      "          [  35,  -84,    2],\n",
      "          [  96,   -6,   58]]],\n",
      "\n",
      "\n",
      "        [[[ -65,  -86,   48],\n",
      "          [  -9,  109,  -30],\n",
      "          [  45,  -60,  -36]],\n",
      "\n",
      "         [[  55,  -59,   56],\n",
      "          [  57,  -93,  -24],\n",
      "          [ -91,  -68,   65]],\n",
      "\n",
      "         [[ -46,   59,  -81],\n",
      "          [  -5,  -15,  -30],\n",
      "          [ -33,  -38,   92]]],\n",
      "\n",
      "\n",
      "        [[[ -61,  -43, -101],\n",
      "          [  76,  -20,    4],\n",
      "          [ -76,  -85,   -6]],\n",
      "\n",
      "         [[ -81,   64,  -17],\n",
      "          [  33,   42,   25],\n",
      "          [ -47,  -21,  -28]],\n",
      "\n",
      "         [[ -20,   91,  -15],\n",
      "          [ -13,   66,   -5],\n",
      "          [  45,   89,   -6]]],\n",
      "\n",
      "\n",
      "        [[[ 103,   99,    8],\n",
      "          [  83,  -25,  -77],\n",
      "          [ -63,  -37,   78]],\n",
      "\n",
      "         [[  95,  -50, -101],\n",
      "          [ -66,   37,  -40],\n",
      "          [  41,  -64,   69]],\n",
      "\n",
      "         [[ -77,  -76,  -12],\n",
      "          [ 112,   -2,  -34],\n",
      "          [  84,  -80,  -44]]],\n",
      "\n",
      "\n",
      "        [[[  81,   45,   60],\n",
      "          [  47, -103,   12],\n",
      "          [ -51,    1,  -21]],\n",
      "\n",
      "         [[  68,   28,   43],\n",
      "          [ -32,   67,   -1],\n",
      "          [  84,  -20,   65]],\n",
      "\n",
      "         [[ -64,   60,  -96],\n",
      "          [ -81,  -35,  -59],\n",
      "          [ -28,  -53, -104]]],\n",
      "\n",
      "\n",
      "        [[[  43,   72,  -58],\n",
      "          [  76,  -68,  -30],\n",
      "          [  -7,    3,   56]],\n",
      "\n",
      "         [[  65,  -25,  -19],\n",
      "          [ -66,  -32,  -85],\n",
      "          [  92,  -27, -113]],\n",
      "\n",
      "         [[ -73,  103,  -58],\n",
      "          [ 116,  100,   57],\n",
      "          [  24,  -82,  -66]]],\n",
      "\n",
      "\n",
      "        [[[ -44,   35,  -42],\n",
      "          [ -70,   32,  -16],\n",
      "          [ -59,  -27,   18]],\n",
      "\n",
      "         [[  22,  -68,   35],\n",
      "          [ -11,   18,  -41],\n",
      "          [   5,  -84,  119]],\n",
      "\n",
      "         [[ -19,   95,   61],\n",
      "          [  28,  -49,  102],\n",
      "          [ -73,  -68,  -33]]],\n",
      "\n",
      "\n",
      "        [[[  17,   83,   39],\n",
      "          [ -55,   12,  -62],\n",
      "          [ -28,   40,   33]],\n",
      "\n",
      "         [[ -68,   16,   44],\n",
      "          [   4,   26,   22],\n",
      "          [  10,   77,    2]],\n",
      "\n",
      "         [[  67,   68,  -57],\n",
      "          [ -61,   77,  -35],\n",
      "          [  77,  -66,   38]]],\n",
      "\n",
      "\n",
      "        [[[   5, -101,   88],\n",
      "          [ -78,  -51,  -40],\n",
      "          [  41,   70,   71]],\n",
      "\n",
      "         [[ -44, -103,  -61],\n",
      "          [  54,   28,   82],\n",
      "          [ -30,  -75,  103]],\n",
      "\n",
      "         [[ -40,  -66,  -67],\n",
      "          [ -35,   68,  -47],\n",
      "          [  59,   66,   91]]],\n",
      "\n",
      "\n",
      "        [[[  78,   -4,   73],\n",
      "          [  74,  -98,   22],\n",
      "          [ -75,   50,    2]],\n",
      "\n",
      "         [[   1,  -72,  -21],\n",
      "          [   1,   57,   83],\n",
      "          [  61,   78,   26]],\n",
      "\n",
      "         [[-103,   48, -114],\n",
      "          [ -98,   -3,  -44],\n",
      "          [  43, -119,   53]]],\n",
      "\n",
      "\n",
      "        [[[  71,    3,   30],\n",
      "          [ -46,  -86,  -43],\n",
      "          [ -27,    9,   62]],\n",
      "\n",
      "         [[   5,  -60,  -72],\n",
      "          [ -67,   66,   -6],\n",
      "          [  20,   87,   76]],\n",
      "\n",
      "         [[ -42,   38,    7],\n",
      "          [  85,  -72,  -27],\n",
      "          [   3,  -67,   -6]]],\n",
      "\n",
      "\n",
      "        [[[   4,   64,    9],\n",
      "          [ -72,  -18,   36],\n",
      "          [  19,  -19,  -64]],\n",
      "\n",
      "         [[ -29,  -51,   14],\n",
      "          [  92,  -20,  -98],\n",
      "          [  -5,  -79,  -89]],\n",
      "\n",
      "         [[  95,   56,  -23],\n",
      "          [  29,  -26,   18],\n",
      "          [  90,  -56,   64]]],\n",
      "\n",
      "\n",
      "        [[[  24,  -30,   74],\n",
      "          [ -68,   85,   -8],\n",
      "          [  66,   -6,  -79]],\n",
      "\n",
      "         [[ -28,  -50,   83],\n",
      "          [ -16,  -30,  -89],\n",
      "          [  12,  -88,    2]],\n",
      "\n",
      "         [[  -5,  -47,  -66],\n",
      "          [ -28,  -31,   71],\n",
      "          [ -36,   99,  -60]]],\n",
      "\n",
      "\n",
      "        [[[ -55,   98,  -91],\n",
      "          [ -70,  -45,   21],\n",
      "          [  97,  -29,  -63]],\n",
      "\n",
      "         [[ -75,   51,   90],\n",
      "          [  96,   62,   43],\n",
      "          [ -38,  -42,    4]],\n",
      "\n",
      "         [[ -22,   31,  -27],\n",
      "          [  31,  -83,  -46],\n",
      "          [  31,  -31,  -88]]],\n",
      "\n",
      "\n",
      "        [[[  61,   81,   64],\n",
      "          [ -99,   17,   66],\n",
      "          [ -32,   -4,   53]],\n",
      "\n",
      "         [[ -94,   45,  -26],\n",
      "          [  16,  -35,  -71],\n",
      "          [-108,  -91,   49]],\n",
      "\n",
      "         [[ -29,   64,   34],\n",
      "          [ -53,  -67,    2],\n",
      "          [  59,   63,   43]]],\n",
      "\n",
      "\n",
      "        [[[  42,  -63,  -21],\n",
      "          [  66,   98,   64],\n",
      "          [ -52,  -78,   38]],\n",
      "\n",
      "         [[ -80,  -43,   38],\n",
      "          [ -42,  -27,   24],\n",
      "          [ -62,  -81,   -1]],\n",
      "\n",
      "         [[ -42,   -9,   96],\n",
      "          [ -30,   48,  108],\n",
      "          [   0,  -20,  -14]]],\n",
      "\n",
      "\n",
      "        [[[ -73,    4,   75],\n",
      "          [ -39,  -13,  -95],\n",
      "          [  76,  -23,   15]],\n",
      "\n",
      "         [[ -18,  -11,   95],\n",
      "          [   3,   89,  -79],\n",
      "          [  59,  -44,   34]],\n",
      "\n",
      "         [[  98,   21,   21],\n",
      "          [ -56,  -16,  -51],\n",
      "          [  54,  -60,  -74]]],\n",
      "\n",
      "\n",
      "        [[[ -97,   64,   69],\n",
      "          [ -10,   23,    7],\n",
      "          [ -37,   -9,   82]],\n",
      "\n",
      "         [[  67,   54,   69],\n",
      "          [  19,  -63,   -6],\n",
      "          [  15,   28,   68]],\n",
      "\n",
      "         [[  -7,  -40,   75],\n",
      "          [ -25,   19,  -37],\n",
      "          [  80,   71,  -27]]],\n",
      "\n",
      "\n",
      "        [[[  98,  -72,  -27],\n",
      "          [ -54,  -62,  -57],\n",
      "          [  62,  -71,   94]],\n",
      "\n",
      "         [[  78,  -86,  -14],\n",
      "          [ -70,   23,  -35],\n",
      "          [ -18,  -24,   99]],\n",
      "\n",
      "         [[  56,  -37,  -13],\n",
      "          [ -11,   88,  -63],\n",
      "          [  12,   54,  -24]]],\n",
      "\n",
      "\n",
      "        [[[  78,  -76,   28],\n",
      "          [  28,  -19,  -11],\n",
      "          [ -73,   18,   25]],\n",
      "\n",
      "         [[ -91,    9,   50],\n",
      "          [  33,  -84,   10],\n",
      "          [ -30,  -17,   25]],\n",
      "\n",
      "         [[ -76,   37,   11],\n",
      "          [ -85,  -26,   75],\n",
      "          [ -71,   61,  -13]]],\n",
      "\n",
      "\n",
      "        [[[  20,   24,  -72],\n",
      "          [  83,   98,    1],\n",
      "          [  30,  -66,  -84]],\n",
      "\n",
      "         [[-100,   49,  -33],\n",
      "          [  -3,   32,  -49],\n",
      "          [ -17,  -53,  -15]],\n",
      "\n",
      "         [[ -11,    3,   33],\n",
      "          [  99,  -60,  -71],\n",
      "          [ -73,   18,   91]]],\n",
      "\n",
      "\n",
      "        [[[ -53,  -92,   87],\n",
      "          [  76,   20,  -47],\n",
      "          [ -50,  -16,   52]],\n",
      "\n",
      "         [[  86,  -14,   75],\n",
      "          [  55,  -91,  -13],\n",
      "          [ -13,   13, -100]],\n",
      "\n",
      "         [[ -24,   36,   16],\n",
      "          [  20,   52, -100],\n",
      "          [   9,   69,  -55]]],\n",
      "\n",
      "\n",
      "        [[[ -48,  -44,  -84],\n",
      "          [ -71,   69,  -49],\n",
      "          [  41,   -5,   47]],\n",
      "\n",
      "         [[ -16,   66,  -31],\n",
      "          [  60,  -63,  -99],\n",
      "          [ -68,  -61,  -87]],\n",
      "\n",
      "         [[  94,  -30,   74],\n",
      "          [ -62,   89,  -55],\n",
      "          [  68,  -79,    1]]],\n",
      "\n",
      "\n",
      "        [[[ -53,  -23,  -42],\n",
      "          [ -32,  -42,   -2],\n",
      "          [ -47,  -36,  -15]],\n",
      "\n",
      "         [[  -1,   52,   89],\n",
      "          [  59,  -35,   79],\n",
      "          [   6,  -74,  -37]],\n",
      "\n",
      "         [[  92,   16,   77],\n",
      "          [  30,   93,  -70],\n",
      "          [  47,  -44,  -53]]],\n",
      "\n",
      "\n",
      "        [[[  12,  -58,  -31],\n",
      "          [  -7,   35,   71],\n",
      "          [  13,   14,  -69]],\n",
      "\n",
      "         [[  52,   30,    1],\n",
      "          [ 105,   46,  -91],\n",
      "          [  77,  -51,   82]],\n",
      "\n",
      "         [[  52,  -32,  -41],\n",
      "          [   7,   26,  -70],\n",
      "          [ -68,   27, -127]]],\n",
      "\n",
      "\n",
      "        [[[  93,  -30,   17],\n",
      "          [  12,   65,   19],\n",
      "          [  10,  -36,  -29]],\n",
      "\n",
      "         [[  95,  -28,    9],\n",
      "          [ -74,    4,   71],\n",
      "          [ -90,  -52,  -94]],\n",
      "\n",
      "         [[  55,   25,  -68],\n",
      "          [  50,  -40,  -60],\n",
      "          [  -1,  101,  -80]]]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "# Print the weights matrix of the model before quantization\n",
    "print(\"Weights before quantization\")\n",
    "print(torch.int_repr(net_quant.conv1.weight()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8810dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión total: 82.61%\n"
     ]
    }
   ],
   "source": [
    "test(net_quant)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
