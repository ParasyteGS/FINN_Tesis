{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cde1394e",
   "metadata": {},
   "source": [
    "Pytorch CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a44e9d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 100)  # Ajusta según el tamaño de entrada\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(100, 2)  # 2 clases: ave y no ave\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d34f28c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transformaciones: ajustar tamaño y normalizar\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.3, saturation=0.3),\n",
    "        transforms.RandomResizedCrop(64, scale=(0.8, 1.0)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ]\n",
    ")\n",
    "val_dataset = ImageFolder(root=\"dataset_split/val\", transform=val_transform)\n",
    "\n",
    "\n",
    "train_dataset = ImageFolder(root=\"dataset_split/train\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdcad102",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "net = CustomCNN().to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "731b5a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "def train(num_epochs,model):\n",
    "    criterion = nn.CrossEntropyLoss()  # Para clasificación multiclase\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"max\", factor=0.5, patience=3\n",
    "    )\n",
    "    for epoch in range(num_epochs):\n",
    "    # --- Entrenamiento ---\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        train_acc = 100 * correct / total\n",
    "\n",
    "        # --- Validación ---\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0           \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "            f\"Loss: {running_loss/len(train_loader):.4f} - \"\n",
    "            f\"Train Acc: {train_acc:.2f}% - \"\n",
    "            f\"Val Acc: {val_acc:.2f}%\"\n",
    "        )\n",
    "\n",
    "        scheduler.step(val_acc) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8af66bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Loss: 0.6905 - Train Acc: 52.88% - Val Acc: 71.64%\n",
      "Epoch 2/30 - Loss: 0.6590 - Train Acc: 66.25% - Val Acc: 69.15%\n",
      "Epoch 3/30 - Loss: 0.6516 - Train Acc: 61.62% - Val Acc: 68.66%\n",
      "Epoch 4/30 - Loss: 0.5928 - Train Acc: 68.50% - Val Acc: 76.12%\n",
      "Epoch 5/30 - Loss: 0.5627 - Train Acc: 73.00% - Val Acc: 80.10%\n",
      "Epoch 6/30 - Loss: 0.5681 - Train Acc: 71.62% - Val Acc: 70.65%\n",
      "Epoch 7/30 - Loss: 0.5450 - Train Acc: 74.00% - Val Acc: 79.10%\n",
      "Epoch 8/30 - Loss: 0.5177 - Train Acc: 75.50% - Val Acc: 79.60%\n",
      "Epoch 9/30 - Loss: 0.5046 - Train Acc: 75.25% - Val Acc: 75.62%\n",
      "Epoch 10/30 - Loss: 0.4979 - Train Acc: 75.88% - Val Acc: 79.10%\n",
      "Epoch 11/30 - Loss: 0.4950 - Train Acc: 76.25% - Val Acc: 81.09%\n",
      "Epoch 12/30 - Loss: 0.4736 - Train Acc: 78.50% - Val Acc: 78.11%\n",
      "Epoch 13/30 - Loss: 0.4871 - Train Acc: 77.12% - Val Acc: 79.60%\n",
      "Epoch 14/30 - Loss: 0.4614 - Train Acc: 79.25% - Val Acc: 80.10%\n",
      "Epoch 15/30 - Loss: 0.4667 - Train Acc: 79.00% - Val Acc: 81.09%\n",
      "Epoch 16/30 - Loss: 0.4586 - Train Acc: 79.25% - Val Acc: 79.10%\n",
      "Epoch 17/30 - Loss: 0.4312 - Train Acc: 81.00% - Val Acc: 81.59%\n",
      "Epoch 18/30 - Loss: 0.4397 - Train Acc: 80.62% - Val Acc: 83.08%\n",
      "Epoch 19/30 - Loss: 0.4439 - Train Acc: 81.12% - Val Acc: 81.59%\n",
      "Epoch 20/30 - Loss: 0.4395 - Train Acc: 79.62% - Val Acc: 82.59%\n",
      "Epoch 21/30 - Loss: 0.4375 - Train Acc: 80.88% - Val Acc: 80.60%\n",
      "Epoch 22/30 - Loss: 0.4290 - Train Acc: 80.62% - Val Acc: 80.10%\n",
      "Epoch 23/30 - Loss: 0.4247 - Train Acc: 81.62% - Val Acc: 80.10%\n",
      "Epoch 24/30 - Loss: 0.4262 - Train Acc: 80.50% - Val Acc: 79.60%\n",
      "Epoch 25/30 - Loss: 0.4179 - Train Acc: 80.88% - Val Acc: 80.60%\n",
      "Epoch 26/30 - Loss: 0.4098 - Train Acc: 82.88% - Val Acc: 80.10%\n",
      "Epoch 27/30 - Loss: 0.4031 - Train Acc: 81.88% - Val Acc: 79.60%\n",
      "Epoch 28/30 - Loss: 0.4032 - Train Acc: 82.50% - Val Acc: 81.09%\n",
      "Epoch 29/30 - Loss: 0.4273 - Train Acc: 82.12% - Val Acc: 79.10%\n",
      "Epoch 30/30 - Loss: 0.4013 - Train Acc: 82.75% - Val Acc: 82.09%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp_delme.p\")\n",
    "    print(\"Size(KB):\", os.path.getsize(\"temp_delme.p\")/1e3)\n",
    "    os.remove('temp_delme.p')\n",
    "\n",
    "MODEL_FILENAME = 'tinyCNN.pt'\n",
    "\n",
    "if Path(MODEL_FILENAME).exists():\n",
    "    net.load_state_dict(torch.load (MODEL_FILENAME ) )\n",
    "    print( ' Loaded model from disk')\n",
    "else:\n",
    "    train(num_epochs, net)\n",
    "    # Save the model to disk\n",
    "    torch.save(net.state_dict(), MODEL_FILENAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9656f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for quantization\n",
      "Parameter containing:\n",
      "tensor([[[[-1.6515e-01,  2.1807e-01, -1.7042e-02],\n",
      "          [-1.8199e-02,  8.6198e-02,  1.9746e-03],\n",
      "          [-7.7824e-02,  2.1910e-02, -2.6301e-02]],\n",
      "\n",
      "         [[-4.4202e-02, -5.2773e-02, -1.6734e-01],\n",
      "          [-2.2692e-02, -1.7671e-01, -1.1619e-01],\n",
      "          [ 1.0103e-01,  5.2116e-02, -8.0960e-02]],\n",
      "\n",
      "         [[-1.6551e-01,  1.9344e-01, -2.7482e-02],\n",
      "          [-1.7917e-01,  1.7208e-01, -1.5584e-01],\n",
      "          [-8.8777e-02,  9.3557e-02,  4.1366e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3175e-01,  5.3676e-03,  1.1814e-01],\n",
      "          [ 1.2859e-01, -1.3982e-01,  3.0599e-02],\n",
      "          [ 7.9608e-02, -2.1340e-03,  1.5894e-01]],\n",
      "\n",
      "         [[-1.5243e-01, -8.2030e-03,  1.2523e-01],\n",
      "          [ 7.2440e-02, -4.3358e-02,  8.2299e-02],\n",
      "          [ 2.7266e-02,  1.0743e-01, -1.3667e-01]],\n",
      "\n",
      "         [[ 8.1704e-02,  1.4884e-02,  1.0262e-01],\n",
      "          [ 4.3082e-02, -6.7385e-02,  1.2704e-01],\n",
      "          [ 2.4735e-02, -4.9994e-02,  1.5812e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5023e-02,  1.5390e-01,  1.9882e-01],\n",
      "          [-1.2335e-01, -1.0614e-01, -1.1579e-01],\n",
      "          [-4.3041e-03,  1.8139e-02, -6.2463e-02]],\n",
      "\n",
      "         [[-1.3703e-01, -1.3027e-01,  1.4274e-01],\n",
      "          [ 5.3091e-02, -2.7636e-02,  1.9127e-02],\n",
      "          [ 7.9392e-02,  7.1402e-02,  3.0799e-03]],\n",
      "\n",
      "         [[-1.5484e-01, -6.5913e-02,  5.1603e-02],\n",
      "          [ 8.1291e-02,  1.4659e-02, -1.1468e-01],\n",
      "          [ 7.9520e-02, -1.5734e-01, -1.7215e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.9476e-02, -1.8476e-02, -4.9488e-02],\n",
      "          [-1.6099e-01, -5.0004e-02, -6.5756e-04],\n",
      "          [-1.2584e-01, -1.1540e-01, -5.0703e-02]],\n",
      "\n",
      "         [[-1.7949e-01,  7.4811e-02,  7.4367e-02],\n",
      "          [ 1.2601e-01,  1.7365e-01,  2.9945e-03],\n",
      "          [-9.7408e-02,  1.8852e-01,  1.9664e-01]],\n",
      "\n",
      "         [[-1.1977e-01,  1.1880e-01, -1.2498e-01],\n",
      "          [-8.7981e-02,  1.0486e-01,  4.9092e-02],\n",
      "          [ 6.7482e-02,  7.5526e-02, -9.7201e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5672e-01, -9.4971e-02, -1.3950e-01],\n",
      "          [-8.6358e-02,  1.1933e-01,  1.5155e-01],\n",
      "          [-8.8799e-02,  6.4444e-02,  1.8877e-01]],\n",
      "\n",
      "         [[-1.7525e-01, -1.3070e-01, -4.7339e-02],\n",
      "          [-1.8799e-01, -1.9028e-01,  1.4120e-01],\n",
      "          [-1.5191e-02,  1.3915e-01,  1.0645e-01]],\n",
      "\n",
      "         [[ 3.0994e-02,  1.1089e-01,  6.4237e-02],\n",
      "          [ 6.5565e-02,  9.1002e-02,  9.6123e-02],\n",
      "          [ 1.7809e-01, -1.3396e-01, -1.1751e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6584e-01, -3.5527e-02,  2.0714e-01],\n",
      "          [ 2.0229e-02,  4.8500e-02, -1.3769e-01],\n",
      "          [-4.6528e-02, -6.0625e-02, -2.1959e-02]],\n",
      "\n",
      "         [[-1.3485e-01, -1.4379e-01, -1.8361e-01],\n",
      "          [-8.0987e-03,  4.9921e-02, -1.8439e-01],\n",
      "          [-6.3015e-02,  1.6619e-01,  2.3974e-02]],\n",
      "\n",
      "         [[-2.0487e-02,  3.5677e-02,  1.6106e-01],\n",
      "          [ 1.6142e-01,  4.5461e-02, -9.8334e-02],\n",
      "          [ 3.3528e-02, -8.4603e-03, -6.7215e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7345e-02, -2.0315e-01, -2.2196e-02],\n",
      "          [ 9.8186e-02,  1.3647e-01,  4.3801e-02],\n",
      "          [ 1.1835e-01,  1.2323e-01,  7.6503e-02]],\n",
      "\n",
      "         [[ 1.6007e-01,  5.9426e-02, -5.1741e-02],\n",
      "          [ 1.1915e-01,  5.3954e-02, -4.2891e-02],\n",
      "          [-9.0990e-02,  1.4753e-01,  1.8977e-01]],\n",
      "\n",
      "         [[-1.5576e-01,  8.5102e-02, -1.3783e-01],\n",
      "          [-1.4659e-01, -1.9828e-01, -7.4079e-02],\n",
      "          [-2.2165e-02,  1.2042e-02, -9.5236e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.3658e-02, -1.2403e-01, -1.0744e-01],\n",
      "          [-1.5791e-01, -5.6678e-02, -2.6526e-02],\n",
      "          [-1.0523e-01, -6.8909e-02,  1.7287e-01]],\n",
      "\n",
      "         [[ 7.8312e-02,  7.7504e-02,  2.0626e-01],\n",
      "          [ 1.3879e-01,  7.7278e-02,  4.1160e-02],\n",
      "          [ 1.7854e-01, -1.3733e-01,  5.3290e-02]],\n",
      "\n",
      "         [[ 8.9227e-02, -7.3974e-02, -6.3832e-02],\n",
      "          [ 4.1598e-02, -8.2233e-02,  1.0891e-01],\n",
      "          [-1.5911e-01, -9.1673e-02, -1.1845e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.9538e-02, -2.2263e-02,  2.2682e-01],\n",
      "          [-2.6928e-02,  1.3570e-01,  1.4626e-01],\n",
      "          [ 4.9492e-03, -1.1943e-01, -8.6487e-02]],\n",
      "\n",
      "         [[ 1.4674e-01, -2.3135e-02, -7.1147e-02],\n",
      "          [-5.9379e-02, -5.1467e-02,  8.1937e-02],\n",
      "          [-1.7135e-01, -2.5855e-01, -1.8582e-01]],\n",
      "\n",
      "         [[ 2.0539e-01, -7.7234e-02,  1.4135e-01],\n",
      "          [ 1.3968e-01,  2.4756e-02, -1.1568e-01],\n",
      "          [ 6.0720e-02,  3.7893e-02, -1.5760e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6523e-01,  9.3605e-02, -2.9977e-02],\n",
      "          [-3.5917e-02,  2.1149e-01,  1.4661e-03],\n",
      "          [ 1.5857e-01,  1.5167e-01,  2.0161e-01]],\n",
      "\n",
      "         [[-1.1530e-01, -1.6163e-01, -5.9140e-02],\n",
      "          [-1.5837e-01, -6.8883e-02,  1.5899e-02],\n",
      "          [-1.5073e-01, -1.2009e-01,  3.2843e-02]],\n",
      "\n",
      "         [[-1.0017e-01, -8.4180e-02,  1.9692e-01],\n",
      "          [ 1.9261e-01,  4.2995e-02,  1.4886e-01],\n",
      "          [-1.4556e-01,  2.0173e-01, -1.3017e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0721e-01, -1.4250e-01,  1.5502e-01],\n",
      "          [ 1.2174e-01,  7.8582e-02, -8.9761e-02],\n",
      "          [-8.3153e-02, -1.0947e-01,  5.9523e-02]],\n",
      "\n",
      "         [[-1.3767e-01,  2.6645e-02,  1.2452e-01],\n",
      "          [-7.1028e-02,  1.7582e-01,  1.1422e-01],\n",
      "          [-1.1276e-01,  4.6185e-02, -1.5783e-01]],\n",
      "\n",
      "         [[ 2.8825e-02, -1.0377e-01,  3.4727e-02],\n",
      "          [ 1.1753e-01,  1.9236e-01,  8.2904e-02],\n",
      "          [-2.0844e-01,  1.7622e-01, -2.3977e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2647e-01,  1.7493e-01,  6.3513e-02],\n",
      "          [ 1.6886e-02,  1.4667e-01, -6.7690e-02],\n",
      "          [-1.3288e-01,  6.0227e-02,  4.1045e-02]],\n",
      "\n",
      "         [[ 8.5843e-02, -1.2802e-03, -1.1132e-01],\n",
      "          [-4.9838e-02,  7.7557e-02, -1.7657e-01],\n",
      "          [ 1.3242e-01, -6.2608e-02, -1.0374e-01]],\n",
      "\n",
      "         [[-1.4168e-02, -3.7469e-02, -3.1715e-02],\n",
      "          [-1.1627e-01,  1.2787e-01,  1.5048e-01],\n",
      "          [ 3.4351e-02,  1.5553e-01, -4.9600e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6484e-01, -3.8514e-02, -1.6207e-01],\n",
      "          [ 1.9476e-01,  1.8944e-01, -5.1946e-02],\n",
      "          [-1.1230e-01,  2.0496e-04,  1.4314e-01]],\n",
      "\n",
      "         [[-4.0211e-02,  1.0985e-01,  1.4296e-01],\n",
      "          [-5.4764e-02, -7.8658e-02, -7.1967e-02],\n",
      "          [-5.1653e-02, -1.1911e-01, -1.2709e-01]],\n",
      "\n",
      "         [[-1.0237e-01, -6.9065e-02,  3.0406e-02],\n",
      "          [ 1.6954e-01,  3.4889e-02, -1.2876e-01],\n",
      "          [-6.5947e-02, -1.6307e-02,  9.9377e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5434e-02, -1.1834e-01,  1.6964e-01],\n",
      "          [ 1.5572e-02,  1.5018e-01, -2.2002e-02],\n",
      "          [-1.0428e-01, -3.9548e-03,  1.3720e-01]],\n",
      "\n",
      "         [[-1.8842e-01, -1.0724e-01, -1.9145e-01],\n",
      "          [-5.0627e-02, -4.0309e-02,  9.0170e-03],\n",
      "          [ 8.2917e-02, -1.1465e-01, -3.6135e-03]],\n",
      "\n",
      "         [[ 1.3255e-01,  6.3226e-02, -1.5303e-01],\n",
      "          [ 1.6712e-01,  4.9614e-02,  1.4509e-01],\n",
      "          [-2.2011e-02, -1.3945e-01,  1.4233e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1343e-01, -7.6869e-02,  1.2880e-01],\n",
      "          [-2.1743e-01,  9.9190e-02,  1.1009e-01],\n",
      "          [-1.2939e-01, -7.3032e-02, -4.7598e-02]],\n",
      "\n",
      "         [[-1.5539e-01, -1.9479e-02, -3.3414e-02],\n",
      "          [ 1.2405e-02,  8.0783e-02,  8.4537e-02],\n",
      "          [-1.9348e-01,  4.5798e-02, -1.3783e-01]],\n",
      "\n",
      "         [[ 1.6053e-02,  1.2910e-01, -3.8265e-02],\n",
      "          [-6.7816e-02,  9.3940e-02,  1.2807e-01],\n",
      "          [ 1.7728e-01,  1.7246e-01,  1.7507e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.8843e-02,  1.1300e-01,  8.1220e-02],\n",
      "          [-1.0222e-01, -3.4794e-02,  7.6174e-02],\n",
      "          [-1.6721e-01,  6.7174e-02,  4.8174e-02]],\n",
      "\n",
      "         [[-1.4056e-02,  1.8344e-01, -9.7072e-02],\n",
      "          [ 1.5906e-01, -1.5400e-01, -6.4293e-02],\n",
      "          [ 5.1776e-02,  1.4729e-01,  9.9260e-02]],\n",
      "\n",
      "         [[ 7.6173e-02,  1.7485e-01, -7.8376e-02],\n",
      "          [-5.3806e-02, -3.9947e-02, -1.5814e-01],\n",
      "          [-1.8286e-01,  6.6038e-03, -4.5971e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0913e-01, -1.3850e-01, -7.9715e-02],\n",
      "          [-1.4825e-01, -1.5468e-01,  4.6555e-02],\n",
      "          [-8.0228e-02,  4.2861e-02, -1.4876e-01]],\n",
      "\n",
      "         [[ 3.0639e-02,  2.9994e-02, -8.0030e-02],\n",
      "          [ 1.6451e-01, -1.3120e-01, -1.8122e-02],\n",
      "          [ 3.7910e-02,  1.4860e-01, -1.3661e-01]],\n",
      "\n",
      "         [[-9.8632e-03, -8.1343e-03,  1.4999e-01],\n",
      "          [ 7.8610e-02, -7.2416e-02,  1.3231e-01],\n",
      "          [-2.4199e-02, -2.5390e-02,  1.1637e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7643e-03, -7.4776e-02, -3.1524e-02],\n",
      "          [ 7.8546e-02,  6.9883e-02, -2.5295e-02],\n",
      "          [ 2.8668e-02, -2.7969e-02, -4.2594e-02]],\n",
      "\n",
      "         [[ 1.8106e-01,  1.1195e-02, -2.3306e-01],\n",
      "          [ 1.4301e-02,  8.4203e-02,  9.5282e-02],\n",
      "          [ 1.3812e-01, -1.3785e-01, -1.5497e-02]],\n",
      "\n",
      "         [[ 1.2097e-01, -9.9014e-02, -1.7768e-01],\n",
      "          [ 1.2110e-01,  1.0025e-01, -1.8642e-01],\n",
      "          [ 8.6931e-02,  5.7012e-03, -1.7600e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.9513e-02,  1.0106e-02,  5.8429e-02],\n",
      "          [-1.1537e-01,  1.6424e-01,  1.5456e-01],\n",
      "          [-9.6682e-02,  1.1737e-01, -7.7253e-02]],\n",
      "\n",
      "         [[ 1.6573e-01, -3.0160e-02, -1.2532e-01],\n",
      "          [ 1.2418e-01, -9.0424e-02, -6.0315e-02],\n",
      "          [-1.4194e-01,  1.0474e-01, -1.1986e-01]],\n",
      "\n",
      "         [[-1.4082e-01, -3.7812e-03, -3.6663e-02],\n",
      "          [ 9.6354e-03, -1.6046e-01,  1.7458e-01],\n",
      "          [-1.1650e-02,  9.2920e-02, -8.9857e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3115e-03, -1.5099e-01,  1.7775e-01],\n",
      "          [ 1.1001e-01, -1.2552e-01,  6.8159e-02],\n",
      "          [ 1.5095e-01,  9.5145e-02, -7.0569e-02]],\n",
      "\n",
      "         [[-1.5790e-01,  1.1154e-02,  9.7031e-02],\n",
      "          [-1.3137e-01,  9.6297e-02, -2.8093e-02],\n",
      "          [-5.5730e-02, -1.5715e-01,  9.4436e-02]],\n",
      "\n",
      "         [[-1.5511e-01, -1.6429e-01, -1.1153e-01],\n",
      "          [-9.1962e-02, -1.5797e-01,  2.3740e-02],\n",
      "          [-2.1198e-02,  1.0164e-01, -1.6479e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.7415e-02, -5.7087e-02,  1.5452e-01],\n",
      "          [ 1.1130e-01,  9.9365e-02,  1.1968e-01],\n",
      "          [ 1.4323e-02,  5.6580e-02,  1.1431e-02]],\n",
      "\n",
      "         [[-1.3874e-01, -1.0215e-02,  1.5750e-01],\n",
      "          [-2.0751e-01, -1.4462e-01, -9.8378e-02],\n",
      "          [-1.2328e-01,  9.3236e-02, -1.0593e-01]],\n",
      "\n",
      "         [[ 4.3681e-02, -6.6619e-02,  6.8041e-02],\n",
      "          [ 4.6701e-02, -1.5994e-01, -2.8765e-03],\n",
      "          [ 9.0925e-02, -5.5426e-04, -1.8017e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5020e-01,  4.5852e-02,  1.0646e-01],\n",
      "          [ 1.0113e-01, -1.2207e-01, -1.2797e-01],\n",
      "          [ 8.0052e-02,  7.9215e-02, -1.9124e-01]],\n",
      "\n",
      "         [[-3.7459e-02, -1.9487e-01,  1.2231e-01],\n",
      "          [-1.4606e-01,  2.5611e-03, -1.2067e-01],\n",
      "          [-1.4813e-01, -1.0891e-01,  4.2086e-02]],\n",
      "\n",
      "         [[ 2.1563e-02, -1.1654e-01,  1.0335e-01],\n",
      "          [ 1.1154e-01,  1.5948e-01,  1.0794e-01],\n",
      "          [ 6.7089e-03,  9.5144e-02,  1.8880e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6982e-01, -5.6828e-02, -7.9375e-02],\n",
      "          [ 1.4954e-01,  9.0902e-02, -2.8428e-02],\n",
      "          [-4.5975e-02, -9.9701e-02, -9.8986e-03]],\n",
      "\n",
      "         [[ 1.1924e-01,  5.5180e-02,  1.8688e-01],\n",
      "          [-1.6643e-01, -1.4548e-01, -5.6546e-02],\n",
      "          [-1.6818e-01, -1.0637e-01,  6.7326e-02]],\n",
      "\n",
      "         [[-5.5344e-02,  1.7571e-01,  1.5584e-01],\n",
      "          [ 1.9020e-01,  1.2884e-01,  1.8158e-01],\n",
      "          [ 1.8588e-01, -8.0434e-02,  4.7982e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9816e-01,  1.3116e-01, -1.0854e-01],\n",
      "          [ 1.3718e-02, -5.4502e-02, -1.4370e-01],\n",
      "          [-5.6398e-02,  1.8558e-01, -1.6921e-01]],\n",
      "\n",
      "         [[-1.4815e-02, -8.0483e-02, -1.4905e-01],\n",
      "          [-1.8623e-01, -1.0983e-01, -1.9410e-01],\n",
      "          [ 1.0360e-01,  1.7904e-01, -1.9638e-01]],\n",
      "\n",
      "         [[-1.4451e-01, -1.1359e-01, -1.0917e-02],\n",
      "          [ 1.0979e-01,  6.1041e-02,  4.5514e-02],\n",
      "          [ 2.0004e-01,  1.4714e-03,  1.9280e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6109e-01,  2.5246e-02,  4.3462e-02],\n",
      "          [-9.0776e-02, -2.2595e-02,  4.0669e-02],\n",
      "          [ 1.5968e-01, -1.5833e-01,  1.2148e-01]],\n",
      "\n",
      "         [[-1.0211e-01,  1.2174e-01,  1.1184e-01],\n",
      "          [-1.6357e-01,  1.7945e-01,  2.3038e-01],\n",
      "          [-1.3026e-01, -1.2923e-01,  6.6375e-02]],\n",
      "\n",
      "         [[-9.4621e-03, -7.7551e-03, -2.6180e-02],\n",
      "          [-1.3460e-01,  1.5109e-02, -4.3507e-02],\n",
      "          [-7.3434e-02,  1.3007e-01, -1.0304e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4525e-01,  8.8524e-02,  2.5207e-02],\n",
      "          [ 2.2204e-03, -6.1339e-02,  1.8542e-01],\n",
      "          [-1.6728e-01,  9.2719e-02, -6.9236e-02]],\n",
      "\n",
      "         [[-7.3390e-02, -1.4273e-01,  1.2072e-01],\n",
      "          [-2.1794e-03, -1.0410e-01, -5.4074e-02],\n",
      "          [-1.4870e-01,  1.1702e-01,  1.2460e-01]],\n",
      "\n",
      "         [[ 1.8707e-01,  5.4014e-02, -6.6035e-04],\n",
      "          [-1.1016e-01, -9.0894e-02, -1.3473e-01],\n",
      "          [-8.2002e-02,  4.2348e-03,  5.6342e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0220e-02,  6.5665e-02, -1.3776e-01],\n",
      "          [-5.6165e-02, -4.3054e-02, -1.6124e-01],\n",
      "          [-1.6822e-01, -8.9998e-02,  9.9151e-02]],\n",
      "\n",
      "         [[ 1.0626e-01,  1.6897e-01,  7.1174e-02],\n",
      "          [ 8.6993e-02, -1.0324e-01,  3.4080e-02],\n",
      "          [ 1.5680e-01,  1.3339e-01,  4.5323e-03]],\n",
      "\n",
      "         [[-5.3489e-02, -5.1149e-02,  1.1214e-01],\n",
      "          [-2.2498e-01, -2.4158e-02, -5.1087e-02],\n",
      "          [ 1.2803e-01, -1.8276e-01, -5.2959e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.0014e-02, -3.4462e-02,  3.9031e-02],\n",
      "          [ 7.7541e-02, -1.5854e-01,  1.0087e-01],\n",
      "          [-1.9987e-01,  3.9211e-02,  1.0430e-01]],\n",
      "\n",
      "         [[-1.4250e-01,  2.2765e-02, -6.7916e-03],\n",
      "          [-1.7132e-01,  1.8668e-01,  6.2170e-02],\n",
      "          [ 1.6771e-01,  1.4918e-01, -2.6153e-02]],\n",
      "\n",
      "         [[-1.3500e-01,  1.7382e-01,  6.6632e-02],\n",
      "          [-1.9192e-01,  6.1581e-02,  9.9999e-02],\n",
      "          [-1.8889e-01,  6.1994e-02, -1.4435e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2595e-01,  2.5269e-02,  1.9934e-01],\n",
      "          [-1.2419e-01, -1.3583e-01, -7.2848e-02],\n",
      "          [ 1.4775e-02, -1.3090e-01,  7.8648e-02]],\n",
      "\n",
      "         [[ 1.3700e-01, -2.8658e-02, -2.0870e-02],\n",
      "          [-4.7278e-02, -1.2408e-02,  2.1546e-01],\n",
      "          [-1.1948e-01, -3.0173e-03,  2.3325e-01]],\n",
      "\n",
      "         [[-1.1314e-01, -9.0883e-02,  1.8456e-02],\n",
      "          [-1.6291e-01,  4.8757e-02, -1.1043e-01],\n",
      "          [ 3.5056e-02,  2.6586e-03,  2.0378e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1717e-01,  1.7408e-01,  7.9788e-02],\n",
      "          [ 8.7160e-02, -1.4874e-01, -1.5103e-01],\n",
      "          [ 1.9060e-01,  9.5981e-02, -1.9405e-02]],\n",
      "\n",
      "         [[ 1.5681e-02, -2.0265e-01,  5.4118e-02],\n",
      "          [ 1.0285e-01, -7.3159e-02, -1.1211e-01],\n",
      "          [ 1.8939e-01, -1.1255e-01, -1.8772e-01]],\n",
      "\n",
      "         [[-1.6636e-01,  1.2162e-01,  3.1709e-02],\n",
      "          [ 1.2054e-01,  7.4812e-02,  1.0899e-01],\n",
      "          [-3.3600e-02,  2.1505e-02,  2.6525e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0888e-01, -9.2189e-02,  1.0189e-01],\n",
      "          [ 1.2948e-01,  2.3186e-02, -2.5035e-02],\n",
      "          [-1.5042e-01,  1.5455e-01, -1.4937e-01]],\n",
      "\n",
      "         [[ 1.4732e-01, -2.2499e-02, -5.9607e-02],\n",
      "          [-7.0852e-02,  3.0651e-02, -1.1186e-02],\n",
      "          [ 3.6315e-02,  1.5829e-01, -2.6283e-02]],\n",
      "\n",
      "         [[ 1.4200e-01, -1.0296e-01,  1.7661e-01],\n",
      "          [ 1.1762e-01, -5.0923e-02,  1.0588e-01],\n",
      "          [-7.7194e-02, -1.0497e-01,  1.2303e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8467e-01,  1.0155e-01, -2.5727e-02],\n",
      "          [ 5.1777e-02,  1.1060e-01, -1.4446e-01],\n",
      "          [-8.8362e-02,  1.2111e-01, -1.8021e-01]],\n",
      "\n",
      "         [[ 1.1937e-01,  1.6317e-01,  2.4986e-02],\n",
      "          [ 1.3361e-01, -6.9380e-02, -1.0360e-01],\n",
      "          [ 2.5015e-02,  1.0282e-01, -1.4180e-01]],\n",
      "\n",
      "         [[-7.9085e-02,  1.1294e-01, -1.1397e-01],\n",
      "          [ 6.7039e-02,  1.9438e-01,  9.7382e-02],\n",
      "          [ 3.0561e-03, -1.2737e-01,  1.7629e-01]]]], requires_grad=True)\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print('Weight for quantization')\n",
    "print(net.conv1.weight)\n",
    "print(net.conv1.weight.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2fe42134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size(KB): 1788.469\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c9d42f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quant_simple_CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Quant_simple_CustomCNN, self).__init__()\n",
    "\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 100)  # Ajusta según el tamaño de entrada\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(100, 2)  # 2 clases: ave y no ave\n",
    "\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.quant(x)\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        x = self.dequant(x)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a78aacc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\AppData\\Local\\Temp\\ipykernel_20284\\3284402915.py:7: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  net_quant = torch.ao.quantization.prepare(net_quant)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Quant_simple_CustomCNN(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (conv1): Conv2d(\n",
       "    3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(\n",
       "    32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(\n",
       "    64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv2d(\n",
       "    128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(\n",
       "    in_features=2048, out_features=100, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(\n",
       "    in_features=100, out_features=2, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_quant = Quant_simple_CustomCNN().to(device)\n",
    "\n",
    "net_quant.load_state_dict(net.state_dict())\n",
    "net_quant.eval()\n",
    "\n",
    "net_quant.qconfig = torch.ao.quantization.default_qconfig\n",
    "net_quant = torch.ao.quantization.prepare(net_quant) \n",
    "net_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "58e50e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "\n",
    "def test(model, folder=\"Images_test\"):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for class_name in os.listdir(folder):\n",
    "            class_folder = os.path.join(folder, class_name)\n",
    "            if not os.path.isdir(class_folder):\n",
    "                continue\n",
    "\n",
    "            for filename in os.listdir(class_folder):\n",
    "                if filename.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "                    img_path = os.path.join(class_folder, filename)\n",
    "                    img = Image.open(img_path)\n",
    "                    img = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "                    output = model(img)\n",
    "                    pred_class = output.argmax(dim=1).item()\n",
    "\n",
    "                    # Obtenemos el índice de la clase real según train_dataset.classes\n",
    "                    true_class = train_dataset.classes.index(class_name)\n",
    "\n",
    "                    if pred_class == true_class:\n",
    "                        correct += 1\n",
    "                    total += 1\n",
    "\n",
    "\n",
    "    accuracy = 100 * correct / total if total > 0 else 0\n",
    "    print(f\"Precisión total: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6383a26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión total: 78.26%\n"
     ]
    }
   ],
   "source": [
    "test(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a077d287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión total: 78.26%\n"
     ]
    }
   ],
   "source": [
    "test(net_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "68bd0c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check stadistics\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Quant_simple_CustomCNN(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=-1.0, max_val=1.0)\n",
       "  )\n",
       "  (conv1): Conv2d(\n",
       "    3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "    (activation_post_process): MinMaxObserver(min_val=-1.575791597366333, max_val=1.4939677715301514)\n",
       "  )\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(\n",
       "    32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "    (activation_post_process): MinMaxObserver(min_val=-1.544890284538269, max_val=1.4271245002746582)\n",
       "  )\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(\n",
       "    64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "    (activation_post_process): MinMaxObserver(min_val=-0.953361988067627, max_val=1.1487722396850586)\n",
       "  )\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv2d(\n",
       "    128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "    (activation_post_process): MinMaxObserver(min_val=-1.7843440771102905, max_val=1.180371642112732)\n",
       "  )\n",
       "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(\n",
       "    in_features=2048, out_features=100, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=-2.642042398452759, max_val=2.9398484230041504)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(\n",
       "    in_features=100, out_features=2, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=-2.487593173980713, max_val=1.6850148439407349)\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Check stadistics')\n",
    "net_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "79e36a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\AppData\\Local\\Temp\\ipykernel_20284\\1025239621.py:1: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  net_quant = torch.ao.quantization.convert(net_quant)\n"
     ]
    }
   ],
   "source": [
    "net_quant = torch.ao.quantization.convert(net_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "58e4d4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check Stadistics\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Quant_simple_CustomCNN(\n",
       "  (quant): Quantize(scale=tensor([0.0157]), zero_point=tensor([64]), dtype=torch.quint8)\n",
       "  (conv1): QuantizedConv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.024171333760023117, zero_point=65, padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): QuantizedConv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.023401692509651184, zero_point=66, padding=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.016552237793803215, zero_point=58, padding=(1, 1))\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.023344218730926514, zero_point=76, padding=(1, 1))\n",
       "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): QuantizedLinear(in_features=2048, out_features=100, scale=0.04395189881324768, zero_point=60, qscheme=torch.per_tensor_affine)\n",
       "  (dropout): QuantizedDropout(p=0.5, inplace=False)\n",
       "  (fc2): QuantizedLinear(in_features=100, out_features=2, scale=0.03285517916083336, zero_point=76, qscheme=torch.per_tensor_affine)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Check Stadistics\")\n",
    "net_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "72a4fbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weihts quantization\n",
      "tensor([[[[ -81,  108,   -8],\n",
      "          [  -9,   43,    1],\n",
      "          [ -38,   11,  -13]],\n",
      "\n",
      "         [[ -22,  -26,  -83],\n",
      "          [ -11,  -87,  -57],\n",
      "          [  50,   26,  -40]],\n",
      "\n",
      "         [[ -82,   95,  -14],\n",
      "          [ -88,   85,  -77],\n",
      "          [ -44,   46,   20]]],\n",
      "\n",
      "\n",
      "        [[[ -65,    3,   58],\n",
      "          [  63,  -69,   15],\n",
      "          [  39,   -1,   78]],\n",
      "\n",
      "         [[ -75,   -4,   62],\n",
      "          [  36,  -21,   41],\n",
      "          [  13,   53,  -67]],\n",
      "\n",
      "         [[  40,    7,   51],\n",
      "          [  21,  -33,   63],\n",
      "          [  12,  -25,    8]]],\n",
      "\n",
      "\n",
      "        [[[  12,   76,   98],\n",
      "          [ -61,  -52,  -57],\n",
      "          [  -2,    9,  -31]],\n",
      "\n",
      "         [[ -68,  -64,   70],\n",
      "          [  26,  -14,    9],\n",
      "          [  39,   35,    2]],\n",
      "\n",
      "         [[ -76,  -33,   25],\n",
      "          [  40,    7,  -57],\n",
      "          [  39,  -78,  -85]]],\n",
      "\n",
      "\n",
      "        [[[ -44,   -9,  -24],\n",
      "          [ -79,  -25,    0],\n",
      "          [ -62,  -57,  -25]],\n",
      "\n",
      "         [[ -89,   37,   37],\n",
      "          [  62,   86,    1],\n",
      "          [ -48,   93,   97]],\n",
      "\n",
      "         [[ -59,   59,  -62],\n",
      "          [ -43,   52,   24],\n",
      "          [  33,   37,  -48]]],\n",
      "\n",
      "\n",
      "        [[[ -77,  -47,  -69],\n",
      "          [ -43,   59,   75],\n",
      "          [ -44,   32,   93]],\n",
      "\n",
      "         [[ -86,  -64,  -23],\n",
      "          [ -93,  -94,   70],\n",
      "          [  -7,   69,   52]],\n",
      "\n",
      "         [[  15,   55,   32],\n",
      "          [  32,   45,   47],\n",
      "          [  88,  -66,  -58]]],\n",
      "\n",
      "\n",
      "        [[[  82,  -18,  102],\n",
      "          [  10,   24,  -68],\n",
      "          [ -23,  -30,  -11]],\n",
      "\n",
      "         [[ -67,  -71,  -91],\n",
      "          [  -4,   25,  -91],\n",
      "          [ -31,   82,   12]],\n",
      "\n",
      "         [[ -10,   18,   79],\n",
      "          [  80,   22,  -48],\n",
      "          [  17,   -4,  -33]]],\n",
      "\n",
      "\n",
      "        [[[  23, -100,  -11],\n",
      "          [  48,   67,   22],\n",
      "          [  58,   61,   38]],\n",
      "\n",
      "         [[  79,   29,  -26],\n",
      "          [  59,   27,  -21],\n",
      "          [ -45,   73,   94]],\n",
      "\n",
      "         [[ -77,   42,  -68],\n",
      "          [ -72,  -98,  -37],\n",
      "          [ -11,    6,  -47]]],\n",
      "\n",
      "\n",
      "        [[[ -41,  -61,  -53],\n",
      "          [ -78,  -28,  -13],\n",
      "          [ -52,  -34,   85]],\n",
      "\n",
      "         [[  39,   38,  102],\n",
      "          [  68,   38,   20],\n",
      "          [  88,  -68,   26]],\n",
      "\n",
      "         [[  44,  -36,  -31],\n",
      "          [  21,  -41,   54],\n",
      "          [ -78,  -45,  -58]]],\n",
      "\n",
      "\n",
      "        [[[ -15,  -11,  112],\n",
      "          [ -13,   67,   72],\n",
      "          [   2,  -59,  -43]],\n",
      "\n",
      "         [[  72,  -11,  -35],\n",
      "          [ -29,  -25,   40],\n",
      "          [ -84, -128,  -92]],\n",
      "\n",
      "         [[ 101,  -38,   70],\n",
      "          [  69,   12,  -57],\n",
      "          [  30,   19,  -78]]],\n",
      "\n",
      "\n",
      "        [[[ -81,   46,  -15],\n",
      "          [ -18,  104,    1],\n",
      "          [  78,   75,   99]],\n",
      "\n",
      "         [[ -57,  -80,  -29],\n",
      "          [ -78,  -34,    8],\n",
      "          [ -74,  -59,   16]],\n",
      "\n",
      "         [[ -49,  -42,   97],\n",
      "          [  95,   21,   73],\n",
      "          [ -72,   99,  -64]]],\n",
      "\n",
      "\n",
      "        [[[  53,  -70,   76],\n",
      "          [  60,   39,  -44],\n",
      "          [ -41,  -54,   29]],\n",
      "\n",
      "         [[ -68,   13,   61],\n",
      "          [ -35,   87,   56],\n",
      "          [ -56,   23,  -78]],\n",
      "\n",
      "         [[  14,  -51,   17],\n",
      "          [  58,   95,   41],\n",
      "          [-103,   87,  -12]]],\n",
      "\n",
      "\n",
      "        [[[ -62,   86,   31],\n",
      "          [   8,   72,  -33],\n",
      "          [ -66,   30,   20]],\n",
      "\n",
      "         [[  42,   -1,  -55],\n",
      "          [ -25,   38,  -87],\n",
      "          [  65,  -31,  -51]],\n",
      "\n",
      "         [[  -7,  -18,  -16],\n",
      "          [ -57,   63,   74],\n",
      "          [  17,   77,  -24]]],\n",
      "\n",
      "\n",
      "        [[[ -81,  -19,  -80],\n",
      "          [  96,   93,  -26],\n",
      "          [ -55,    0,   71]],\n",
      "\n",
      "         [[ -20,   54,   70],\n",
      "          [ -27,  -39,  -35],\n",
      "          [ -25,  -59,  -63]],\n",
      "\n",
      "         [[ -50,  -34,   15],\n",
      "          [  84,   17,  -63],\n",
      "          [ -33,   -8,   49]]],\n",
      "\n",
      "\n",
      "        [[[  -8,  -58,   84],\n",
      "          [   8,   74,  -11],\n",
      "          [ -51,   -2,   68]],\n",
      "\n",
      "         [[ -93,  -53,  -94],\n",
      "          [ -25,  -20,    4],\n",
      "          [  41,  -57,   -2]],\n",
      "\n",
      "         [[  65,   31,  -75],\n",
      "          [  82,   24,   72],\n",
      "          [ -11,  -69,   70]]],\n",
      "\n",
      "\n",
      "        [[[ -56,  -38,   64],\n",
      "          [-107,   49,   54],\n",
      "          [ -64,  -36,  -23]],\n",
      "\n",
      "         [[ -77,  -10,  -16],\n",
      "          [   6,   40,   42],\n",
      "          [ -95,   23,  -68]],\n",
      "\n",
      "         [[   8,   64,  -19],\n",
      "          [ -33,   46,   63],\n",
      "          [  87,   85,   86]]],\n",
      "\n",
      "\n",
      "        [[[ -19,   56,   40],\n",
      "          [ -50,  -17,   38],\n",
      "          [ -82,   33,   24]],\n",
      "\n",
      "         [[  -7,   90,  -48],\n",
      "          [  78,  -76,  -32],\n",
      "          [  26,   73,   49]],\n",
      "\n",
      "         [[  38,   86,  -39],\n",
      "          [ -27,  -20,  -78],\n",
      "          [ -90,    3,  -23]]],\n",
      "\n",
      "\n",
      "        [[[ -54,  -68,  -39],\n",
      "          [ -73,  -76,   23],\n",
      "          [ -40,   21,  -73]],\n",
      "\n",
      "         [[  15,   15,  -39],\n",
      "          [  81,  -65,   -9],\n",
      "          [  19,   73,  -67]],\n",
      "\n",
      "         [[  -5,   -4,   74],\n",
      "          [  39,  -36,   65],\n",
      "          [ -12,  -13,   57]]],\n",
      "\n",
      "\n",
      "        [[[   2,  -37,  -16],\n",
      "          [  39,   34,  -12],\n",
      "          [  14,  -14,  -21]],\n",
      "\n",
      "         [[  89,    6, -115],\n",
      "          [   7,   42,   47],\n",
      "          [  68,  -68,   -8]],\n",
      "\n",
      "         [[  60,  -49,  -88],\n",
      "          [  60,   49,  -92],\n",
      "          [  43,    3,  -87]]],\n",
      "\n",
      "\n",
      "        [[[  34,    5,   29],\n",
      "          [ -57,   81,   76],\n",
      "          [ -48,   58,  -38]],\n",
      "\n",
      "         [[  82,  -15,  -62],\n",
      "          [  61,  -45,  -30],\n",
      "          [ -70,   52,  -59]],\n",
      "\n",
      "         [[ -69,   -2,  -18],\n",
      "          [   5,  -79,   86],\n",
      "          [  -6,   46,  -44]]],\n",
      "\n",
      "\n",
      "        [[[  -1,  -74,   88],\n",
      "          [  54,  -62,   34],\n",
      "          [  74,   47,  -35]],\n",
      "\n",
      "         [[ -78,    6,   48],\n",
      "          [ -65,   47,  -14],\n",
      "          [ -27,  -77,   47]],\n",
      "\n",
      "         [[ -76,  -81,  -55],\n",
      "          [ -45,  -78,   12],\n",
      "          [ -10,   50,  -81]]],\n",
      "\n",
      "\n",
      "        [[[ -38,  -28,   76],\n",
      "          [  55,   49,   59],\n",
      "          [   7,   28,    6]],\n",
      "\n",
      "         [[ -68,   -5,   78],\n",
      "          [-102,  -71,  -49],\n",
      "          [ -61,   46,  -52]],\n",
      "\n",
      "         [[  22,  -33,   34],\n",
      "          [  23,  -79,   -1],\n",
      "          [  45,    0,   -9]]],\n",
      "\n",
      "\n",
      "        [[[ -74,   23,   52],\n",
      "          [  50,  -60,  -63],\n",
      "          [  39,   39,  -94]],\n",
      "\n",
      "         [[ -18,  -96,   60],\n",
      "          [ -72,    1,  -60],\n",
      "          [ -73,  -54,   21]],\n",
      "\n",
      "         [[  11,  -57,   51],\n",
      "          [  55,   79,   53],\n",
      "          [   3,   47,    9]]],\n",
      "\n",
      "\n",
      "        [[[  84,  -28,  -39],\n",
      "          [  74,   45,  -14],\n",
      "          [ -23,  -49,   -5]],\n",
      "\n",
      "         [[  59,   27,   92],\n",
      "          [ -82,  -72,  -28],\n",
      "          [ -83,  -52,   33]],\n",
      "\n",
      "         [[ -27,   87,   77],\n",
      "          [  94,   64,   90],\n",
      "          [  92,  -40,   24]]],\n",
      "\n",
      "\n",
      "        [[[  98,   65,  -54],\n",
      "          [   7,  -27,  -71],\n",
      "          [ -28,   92,  -83]],\n",
      "\n",
      "         [[  -7,  -40,  -74],\n",
      "          [ -92,  -54,  -96],\n",
      "          [  51,   88,  -97]],\n",
      "\n",
      "         [[ -71,  -56,   -5],\n",
      "          [  54,   30,   22],\n",
      "          [  99,    1,   95]]],\n",
      "\n",
      "\n",
      "        [[[ -79,   12,   21],\n",
      "          [ -45,  -11,   20],\n",
      "          [  79,  -78,   60]],\n",
      "\n",
      "         [[ -50,   60,   55],\n",
      "          [ -81,   88,  114],\n",
      "          [ -64,  -64,   33]],\n",
      "\n",
      "         [[  -5,   -4,  -13],\n",
      "          [ -66,    7,  -21],\n",
      "          [ -36,   64,   -5]]],\n",
      "\n",
      "\n",
      "        [[[ -72,   44,   12],\n",
      "          [   1,  -30,   91],\n",
      "          [ -82,   46,  -34]],\n",
      "\n",
      "         [[ -36,  -70,   60],\n",
      "          [  -1,  -51,  -27],\n",
      "          [ -73,   58,   61]],\n",
      "\n",
      "         [[  92,   27,    0],\n",
      "          [ -54,  -45,  -66],\n",
      "          [ -40,    2,   28]]],\n",
      "\n",
      "\n",
      "        [[[  -5,   32,  -68],\n",
      "          [ -28,  -21,  -80],\n",
      "          [ -83,  -44,   49]],\n",
      "\n",
      "         [[  52,   83,   35],\n",
      "          [  43,  -51,   17],\n",
      "          [  77,   66,    2]],\n",
      "\n",
      "         [[ -26,  -25,   55],\n",
      "          [-111,  -12,  -25],\n",
      "          [  63,  -90,  -26]]],\n",
      "\n",
      "\n",
      "        [[[ -20,  -17,   19],\n",
      "          [  38,  -78,   50],\n",
      "          [ -99,   19,   51]],\n",
      "\n",
      "         [[ -70,   11,   -3],\n",
      "          [ -84,   92,   31],\n",
      "          [  83,   74,  -13]],\n",
      "\n",
      "         [[ -67,   86,   33],\n",
      "          [ -95,   30,   49],\n",
      "          [ -93,   31,  -71]]],\n",
      "\n",
      "\n",
      "        [[[ -62,   12,   98],\n",
      "          [ -61,  -67,  -36],\n",
      "          [   7,  -65,   39]],\n",
      "\n",
      "         [[  68,  -14,  -10],\n",
      "          [ -23,   -6,  106],\n",
      "          [ -59,   -1,  115]],\n",
      "\n",
      "         [[ -56,  -45,    9],\n",
      "          [ -80,   24,  -54],\n",
      "          [  17,    1,  100]]],\n",
      "\n",
      "\n",
      "        [[[ -58,   86,   39],\n",
      "          [  43,  -73,  -74],\n",
      "          [  94,   47,  -10]],\n",
      "\n",
      "         [[   8, -100,   27],\n",
      "          [  51,  -36,  -55],\n",
      "          [  93,  -56,  -93]],\n",
      "\n",
      "         [[ -82,   60,   16],\n",
      "          [  59,   37,   54],\n",
      "          [ -17,   11,   13]]],\n",
      "\n",
      "\n",
      "        [[[ -54,  -45,   50],\n",
      "          [  64,   11,  -12],\n",
      "          [ -74,   76,  -74]],\n",
      "\n",
      "         [[  73,  -11,  -29],\n",
      "          [ -35,   15,   -6],\n",
      "          [  18,   78,  -13]],\n",
      "\n",
      "         [[  70,  -51,   87],\n",
      "          [  58,  -25,   52],\n",
      "          [ -38,  -52,   61]]],\n",
      "\n",
      "\n",
      "        [[[ -91,   50,  -13],\n",
      "          [  26,   55,  -71],\n",
      "          [ -44,   60,  -89]],\n",
      "\n",
      "         [[  59,   80,   12],\n",
      "          [  66,  -34,  -51],\n",
      "          [  12,   51,  -70]],\n",
      "\n",
      "         [[ -39,   56,  -56],\n",
      "          [  33,   96,   48],\n",
      "          [   2,  -63,   87]]]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "# Weights after quantization\n",
    "print(\"Weihts quantization\")\n",
    "print(torch.int_repr(net_quant.conv1.weight()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "736a331e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "Parameter containing:\n",
      "tensor([[[[-1.6515e-01,  2.1807e-01, -1.7042e-02],\n",
      "          [-1.8199e-02,  8.6198e-02,  1.9746e-03],\n",
      "          [-7.7824e-02,  2.1910e-02, -2.6301e-02]],\n",
      "\n",
      "         [[-4.4202e-02, -5.2773e-02, -1.6734e-01],\n",
      "          [-2.2692e-02, -1.7671e-01, -1.1619e-01],\n",
      "          [ 1.0103e-01,  5.2116e-02, -8.0960e-02]],\n",
      "\n",
      "         [[-1.6551e-01,  1.9344e-01, -2.7482e-02],\n",
      "          [-1.7917e-01,  1.7208e-01, -1.5584e-01],\n",
      "          [-8.8777e-02,  9.3557e-02,  4.1366e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3175e-01,  5.3676e-03,  1.1814e-01],\n",
      "          [ 1.2859e-01, -1.3982e-01,  3.0599e-02],\n",
      "          [ 7.9608e-02, -2.1340e-03,  1.5894e-01]],\n",
      "\n",
      "         [[-1.5243e-01, -8.2030e-03,  1.2523e-01],\n",
      "          [ 7.2440e-02, -4.3358e-02,  8.2299e-02],\n",
      "          [ 2.7266e-02,  1.0743e-01, -1.3667e-01]],\n",
      "\n",
      "         [[ 8.1704e-02,  1.4884e-02,  1.0262e-01],\n",
      "          [ 4.3082e-02, -6.7385e-02,  1.2704e-01],\n",
      "          [ 2.4735e-02, -4.9994e-02,  1.5812e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5023e-02,  1.5390e-01,  1.9882e-01],\n",
      "          [-1.2335e-01, -1.0614e-01, -1.1579e-01],\n",
      "          [-4.3041e-03,  1.8139e-02, -6.2463e-02]],\n",
      "\n",
      "         [[-1.3703e-01, -1.3027e-01,  1.4274e-01],\n",
      "          [ 5.3091e-02, -2.7636e-02,  1.9127e-02],\n",
      "          [ 7.9392e-02,  7.1402e-02,  3.0799e-03]],\n",
      "\n",
      "         [[-1.5484e-01, -6.5913e-02,  5.1603e-02],\n",
      "          [ 8.1291e-02,  1.4659e-02, -1.1468e-01],\n",
      "          [ 7.9520e-02, -1.5734e-01, -1.7215e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.9476e-02, -1.8476e-02, -4.9488e-02],\n",
      "          [-1.6099e-01, -5.0004e-02, -6.5756e-04],\n",
      "          [-1.2584e-01, -1.1540e-01, -5.0703e-02]],\n",
      "\n",
      "         [[-1.7949e-01,  7.4811e-02,  7.4367e-02],\n",
      "          [ 1.2601e-01,  1.7365e-01,  2.9945e-03],\n",
      "          [-9.7408e-02,  1.8852e-01,  1.9664e-01]],\n",
      "\n",
      "         [[-1.1977e-01,  1.1880e-01, -1.2498e-01],\n",
      "          [-8.7981e-02,  1.0486e-01,  4.9092e-02],\n",
      "          [ 6.7482e-02,  7.5526e-02, -9.7201e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5672e-01, -9.4971e-02, -1.3950e-01],\n",
      "          [-8.6358e-02,  1.1933e-01,  1.5155e-01],\n",
      "          [-8.8799e-02,  6.4444e-02,  1.8877e-01]],\n",
      "\n",
      "         [[-1.7525e-01, -1.3070e-01, -4.7339e-02],\n",
      "          [-1.8799e-01, -1.9028e-01,  1.4120e-01],\n",
      "          [-1.5191e-02,  1.3915e-01,  1.0645e-01]],\n",
      "\n",
      "         [[ 3.0994e-02,  1.1089e-01,  6.4237e-02],\n",
      "          [ 6.5565e-02,  9.1002e-02,  9.6123e-02],\n",
      "          [ 1.7809e-01, -1.3396e-01, -1.1751e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6584e-01, -3.5527e-02,  2.0714e-01],\n",
      "          [ 2.0229e-02,  4.8500e-02, -1.3769e-01],\n",
      "          [-4.6528e-02, -6.0625e-02, -2.1959e-02]],\n",
      "\n",
      "         [[-1.3485e-01, -1.4379e-01, -1.8361e-01],\n",
      "          [-8.0987e-03,  4.9921e-02, -1.8439e-01],\n",
      "          [-6.3015e-02,  1.6619e-01,  2.3974e-02]],\n",
      "\n",
      "         [[-2.0487e-02,  3.5677e-02,  1.6106e-01],\n",
      "          [ 1.6142e-01,  4.5461e-02, -9.8334e-02],\n",
      "          [ 3.3528e-02, -8.4603e-03, -6.7215e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7345e-02, -2.0315e-01, -2.2196e-02],\n",
      "          [ 9.8186e-02,  1.3647e-01,  4.3801e-02],\n",
      "          [ 1.1835e-01,  1.2323e-01,  7.6503e-02]],\n",
      "\n",
      "         [[ 1.6007e-01,  5.9426e-02, -5.1741e-02],\n",
      "          [ 1.1915e-01,  5.3954e-02, -4.2891e-02],\n",
      "          [-9.0990e-02,  1.4753e-01,  1.8977e-01]],\n",
      "\n",
      "         [[-1.5576e-01,  8.5102e-02, -1.3783e-01],\n",
      "          [-1.4659e-01, -1.9828e-01, -7.4079e-02],\n",
      "          [-2.2165e-02,  1.2042e-02, -9.5236e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.3658e-02, -1.2403e-01, -1.0744e-01],\n",
      "          [-1.5791e-01, -5.6678e-02, -2.6526e-02],\n",
      "          [-1.0523e-01, -6.8909e-02,  1.7287e-01]],\n",
      "\n",
      "         [[ 7.8312e-02,  7.7504e-02,  2.0626e-01],\n",
      "          [ 1.3879e-01,  7.7278e-02,  4.1160e-02],\n",
      "          [ 1.7854e-01, -1.3733e-01,  5.3290e-02]],\n",
      "\n",
      "         [[ 8.9227e-02, -7.3974e-02, -6.3832e-02],\n",
      "          [ 4.1598e-02, -8.2233e-02,  1.0891e-01],\n",
      "          [-1.5911e-01, -9.1673e-02, -1.1845e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.9538e-02, -2.2263e-02,  2.2682e-01],\n",
      "          [-2.6928e-02,  1.3570e-01,  1.4626e-01],\n",
      "          [ 4.9492e-03, -1.1943e-01, -8.6487e-02]],\n",
      "\n",
      "         [[ 1.4674e-01, -2.3135e-02, -7.1147e-02],\n",
      "          [-5.9379e-02, -5.1467e-02,  8.1937e-02],\n",
      "          [-1.7135e-01, -2.5855e-01, -1.8582e-01]],\n",
      "\n",
      "         [[ 2.0539e-01, -7.7234e-02,  1.4135e-01],\n",
      "          [ 1.3968e-01,  2.4756e-02, -1.1568e-01],\n",
      "          [ 6.0720e-02,  3.7893e-02, -1.5760e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6523e-01,  9.3605e-02, -2.9977e-02],\n",
      "          [-3.5917e-02,  2.1149e-01,  1.4661e-03],\n",
      "          [ 1.5857e-01,  1.5167e-01,  2.0161e-01]],\n",
      "\n",
      "         [[-1.1530e-01, -1.6163e-01, -5.9140e-02],\n",
      "          [-1.5837e-01, -6.8883e-02,  1.5899e-02],\n",
      "          [-1.5073e-01, -1.2009e-01,  3.2843e-02]],\n",
      "\n",
      "         [[-1.0017e-01, -8.4180e-02,  1.9692e-01],\n",
      "          [ 1.9261e-01,  4.2995e-02,  1.4886e-01],\n",
      "          [-1.4556e-01,  2.0173e-01, -1.3017e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0721e-01, -1.4250e-01,  1.5502e-01],\n",
      "          [ 1.2174e-01,  7.8582e-02, -8.9761e-02],\n",
      "          [-8.3153e-02, -1.0947e-01,  5.9523e-02]],\n",
      "\n",
      "         [[-1.3767e-01,  2.6645e-02,  1.2452e-01],\n",
      "          [-7.1028e-02,  1.7582e-01,  1.1422e-01],\n",
      "          [-1.1276e-01,  4.6185e-02, -1.5783e-01]],\n",
      "\n",
      "         [[ 2.8825e-02, -1.0377e-01,  3.4727e-02],\n",
      "          [ 1.1753e-01,  1.9236e-01,  8.2904e-02],\n",
      "          [-2.0844e-01,  1.7622e-01, -2.3977e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2647e-01,  1.7493e-01,  6.3513e-02],\n",
      "          [ 1.6886e-02,  1.4667e-01, -6.7690e-02],\n",
      "          [-1.3288e-01,  6.0227e-02,  4.1045e-02]],\n",
      "\n",
      "         [[ 8.5843e-02, -1.2802e-03, -1.1132e-01],\n",
      "          [-4.9838e-02,  7.7557e-02, -1.7657e-01],\n",
      "          [ 1.3242e-01, -6.2608e-02, -1.0374e-01]],\n",
      "\n",
      "         [[-1.4168e-02, -3.7469e-02, -3.1715e-02],\n",
      "          [-1.1627e-01,  1.2787e-01,  1.5048e-01],\n",
      "          [ 3.4351e-02,  1.5553e-01, -4.9600e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6484e-01, -3.8514e-02, -1.6207e-01],\n",
      "          [ 1.9476e-01,  1.8944e-01, -5.1946e-02],\n",
      "          [-1.1230e-01,  2.0496e-04,  1.4314e-01]],\n",
      "\n",
      "         [[-4.0211e-02,  1.0985e-01,  1.4296e-01],\n",
      "          [-5.4764e-02, -7.8658e-02, -7.1967e-02],\n",
      "          [-5.1653e-02, -1.1911e-01, -1.2709e-01]],\n",
      "\n",
      "         [[-1.0237e-01, -6.9065e-02,  3.0406e-02],\n",
      "          [ 1.6954e-01,  3.4889e-02, -1.2876e-01],\n",
      "          [-6.5947e-02, -1.6307e-02,  9.9377e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5434e-02, -1.1834e-01,  1.6964e-01],\n",
      "          [ 1.5572e-02,  1.5018e-01, -2.2002e-02],\n",
      "          [-1.0428e-01, -3.9548e-03,  1.3720e-01]],\n",
      "\n",
      "         [[-1.8842e-01, -1.0724e-01, -1.9145e-01],\n",
      "          [-5.0627e-02, -4.0309e-02,  9.0170e-03],\n",
      "          [ 8.2917e-02, -1.1465e-01, -3.6135e-03]],\n",
      "\n",
      "         [[ 1.3255e-01,  6.3226e-02, -1.5303e-01],\n",
      "          [ 1.6712e-01,  4.9614e-02,  1.4509e-01],\n",
      "          [-2.2011e-02, -1.3945e-01,  1.4233e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1343e-01, -7.6869e-02,  1.2880e-01],\n",
      "          [-2.1743e-01,  9.9190e-02,  1.1009e-01],\n",
      "          [-1.2939e-01, -7.3032e-02, -4.7598e-02]],\n",
      "\n",
      "         [[-1.5539e-01, -1.9479e-02, -3.3414e-02],\n",
      "          [ 1.2405e-02,  8.0783e-02,  8.4537e-02],\n",
      "          [-1.9348e-01,  4.5798e-02, -1.3783e-01]],\n",
      "\n",
      "         [[ 1.6053e-02,  1.2910e-01, -3.8265e-02],\n",
      "          [-6.7816e-02,  9.3940e-02,  1.2807e-01],\n",
      "          [ 1.7728e-01,  1.7246e-01,  1.7507e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.8843e-02,  1.1300e-01,  8.1220e-02],\n",
      "          [-1.0222e-01, -3.4794e-02,  7.6174e-02],\n",
      "          [-1.6721e-01,  6.7174e-02,  4.8174e-02]],\n",
      "\n",
      "         [[-1.4056e-02,  1.8344e-01, -9.7072e-02],\n",
      "          [ 1.5906e-01, -1.5400e-01, -6.4293e-02],\n",
      "          [ 5.1776e-02,  1.4729e-01,  9.9260e-02]],\n",
      "\n",
      "         [[ 7.6173e-02,  1.7485e-01, -7.8376e-02],\n",
      "          [-5.3806e-02, -3.9947e-02, -1.5814e-01],\n",
      "          [-1.8286e-01,  6.6038e-03, -4.5971e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0913e-01, -1.3850e-01, -7.9715e-02],\n",
      "          [-1.4825e-01, -1.5468e-01,  4.6555e-02],\n",
      "          [-8.0228e-02,  4.2861e-02, -1.4876e-01]],\n",
      "\n",
      "         [[ 3.0639e-02,  2.9994e-02, -8.0030e-02],\n",
      "          [ 1.6451e-01, -1.3120e-01, -1.8122e-02],\n",
      "          [ 3.7910e-02,  1.4860e-01, -1.3661e-01]],\n",
      "\n",
      "         [[-9.8632e-03, -8.1343e-03,  1.4999e-01],\n",
      "          [ 7.8610e-02, -7.2416e-02,  1.3231e-01],\n",
      "          [-2.4199e-02, -2.5390e-02,  1.1637e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7643e-03, -7.4776e-02, -3.1524e-02],\n",
      "          [ 7.8546e-02,  6.9883e-02, -2.5295e-02],\n",
      "          [ 2.8668e-02, -2.7969e-02, -4.2594e-02]],\n",
      "\n",
      "         [[ 1.8106e-01,  1.1195e-02, -2.3306e-01],\n",
      "          [ 1.4301e-02,  8.4203e-02,  9.5282e-02],\n",
      "          [ 1.3812e-01, -1.3785e-01, -1.5497e-02]],\n",
      "\n",
      "         [[ 1.2097e-01, -9.9014e-02, -1.7768e-01],\n",
      "          [ 1.2110e-01,  1.0025e-01, -1.8642e-01],\n",
      "          [ 8.6931e-02,  5.7012e-03, -1.7600e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.9513e-02,  1.0106e-02,  5.8429e-02],\n",
      "          [-1.1537e-01,  1.6424e-01,  1.5456e-01],\n",
      "          [-9.6682e-02,  1.1737e-01, -7.7253e-02]],\n",
      "\n",
      "         [[ 1.6573e-01, -3.0160e-02, -1.2532e-01],\n",
      "          [ 1.2418e-01, -9.0424e-02, -6.0315e-02],\n",
      "          [-1.4194e-01,  1.0474e-01, -1.1986e-01]],\n",
      "\n",
      "         [[-1.4082e-01, -3.7812e-03, -3.6663e-02],\n",
      "          [ 9.6354e-03, -1.6046e-01,  1.7458e-01],\n",
      "          [-1.1650e-02,  9.2920e-02, -8.9857e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3115e-03, -1.5099e-01,  1.7775e-01],\n",
      "          [ 1.1001e-01, -1.2552e-01,  6.8159e-02],\n",
      "          [ 1.5095e-01,  9.5145e-02, -7.0569e-02]],\n",
      "\n",
      "         [[-1.5790e-01,  1.1154e-02,  9.7031e-02],\n",
      "          [-1.3137e-01,  9.6297e-02, -2.8093e-02],\n",
      "          [-5.5730e-02, -1.5715e-01,  9.4436e-02]],\n",
      "\n",
      "         [[-1.5511e-01, -1.6429e-01, -1.1153e-01],\n",
      "          [-9.1962e-02, -1.5797e-01,  2.3740e-02],\n",
      "          [-2.1198e-02,  1.0164e-01, -1.6479e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.7415e-02, -5.7087e-02,  1.5452e-01],\n",
      "          [ 1.1130e-01,  9.9365e-02,  1.1968e-01],\n",
      "          [ 1.4323e-02,  5.6580e-02,  1.1431e-02]],\n",
      "\n",
      "         [[-1.3874e-01, -1.0215e-02,  1.5750e-01],\n",
      "          [-2.0751e-01, -1.4462e-01, -9.8378e-02],\n",
      "          [-1.2328e-01,  9.3236e-02, -1.0593e-01]],\n",
      "\n",
      "         [[ 4.3681e-02, -6.6619e-02,  6.8041e-02],\n",
      "          [ 4.6701e-02, -1.5994e-01, -2.8765e-03],\n",
      "          [ 9.0925e-02, -5.5426e-04, -1.8017e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5020e-01,  4.5852e-02,  1.0646e-01],\n",
      "          [ 1.0113e-01, -1.2207e-01, -1.2797e-01],\n",
      "          [ 8.0052e-02,  7.9215e-02, -1.9124e-01]],\n",
      "\n",
      "         [[-3.7459e-02, -1.9487e-01,  1.2231e-01],\n",
      "          [-1.4606e-01,  2.5611e-03, -1.2067e-01],\n",
      "          [-1.4813e-01, -1.0891e-01,  4.2086e-02]],\n",
      "\n",
      "         [[ 2.1563e-02, -1.1654e-01,  1.0335e-01],\n",
      "          [ 1.1154e-01,  1.5948e-01,  1.0794e-01],\n",
      "          [ 6.7089e-03,  9.5144e-02,  1.8880e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6982e-01, -5.6828e-02, -7.9375e-02],\n",
      "          [ 1.4954e-01,  9.0902e-02, -2.8428e-02],\n",
      "          [-4.5975e-02, -9.9701e-02, -9.8986e-03]],\n",
      "\n",
      "         [[ 1.1924e-01,  5.5180e-02,  1.8688e-01],\n",
      "          [-1.6643e-01, -1.4548e-01, -5.6546e-02],\n",
      "          [-1.6818e-01, -1.0637e-01,  6.7326e-02]],\n",
      "\n",
      "         [[-5.5344e-02,  1.7571e-01,  1.5584e-01],\n",
      "          [ 1.9020e-01,  1.2884e-01,  1.8158e-01],\n",
      "          [ 1.8588e-01, -8.0434e-02,  4.7982e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9816e-01,  1.3116e-01, -1.0854e-01],\n",
      "          [ 1.3718e-02, -5.4502e-02, -1.4370e-01],\n",
      "          [-5.6398e-02,  1.8558e-01, -1.6921e-01]],\n",
      "\n",
      "         [[-1.4815e-02, -8.0483e-02, -1.4905e-01],\n",
      "          [-1.8623e-01, -1.0983e-01, -1.9410e-01],\n",
      "          [ 1.0360e-01,  1.7904e-01, -1.9638e-01]],\n",
      "\n",
      "         [[-1.4451e-01, -1.1359e-01, -1.0917e-02],\n",
      "          [ 1.0979e-01,  6.1041e-02,  4.5514e-02],\n",
      "          [ 2.0004e-01,  1.4714e-03,  1.9280e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6109e-01,  2.5246e-02,  4.3462e-02],\n",
      "          [-9.0776e-02, -2.2595e-02,  4.0669e-02],\n",
      "          [ 1.5968e-01, -1.5833e-01,  1.2148e-01]],\n",
      "\n",
      "         [[-1.0211e-01,  1.2174e-01,  1.1184e-01],\n",
      "          [-1.6357e-01,  1.7945e-01,  2.3038e-01],\n",
      "          [-1.3026e-01, -1.2923e-01,  6.6375e-02]],\n",
      "\n",
      "         [[-9.4621e-03, -7.7551e-03, -2.6180e-02],\n",
      "          [-1.3460e-01,  1.5109e-02, -4.3507e-02],\n",
      "          [-7.3434e-02,  1.3007e-01, -1.0304e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4525e-01,  8.8524e-02,  2.5207e-02],\n",
      "          [ 2.2204e-03, -6.1339e-02,  1.8542e-01],\n",
      "          [-1.6728e-01,  9.2719e-02, -6.9236e-02]],\n",
      "\n",
      "         [[-7.3390e-02, -1.4273e-01,  1.2072e-01],\n",
      "          [-2.1794e-03, -1.0410e-01, -5.4074e-02],\n",
      "          [-1.4870e-01,  1.1702e-01,  1.2460e-01]],\n",
      "\n",
      "         [[ 1.8707e-01,  5.4014e-02, -6.6035e-04],\n",
      "          [-1.1016e-01, -9.0894e-02, -1.3473e-01],\n",
      "          [-8.2002e-02,  4.2348e-03,  5.6342e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0220e-02,  6.5665e-02, -1.3776e-01],\n",
      "          [-5.6165e-02, -4.3054e-02, -1.6124e-01],\n",
      "          [-1.6822e-01, -8.9998e-02,  9.9151e-02]],\n",
      "\n",
      "         [[ 1.0626e-01,  1.6897e-01,  7.1174e-02],\n",
      "          [ 8.6993e-02, -1.0324e-01,  3.4080e-02],\n",
      "          [ 1.5680e-01,  1.3339e-01,  4.5323e-03]],\n",
      "\n",
      "         [[-5.3489e-02, -5.1149e-02,  1.1214e-01],\n",
      "          [-2.2498e-01, -2.4158e-02, -5.1087e-02],\n",
      "          [ 1.2803e-01, -1.8276e-01, -5.2959e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.0014e-02, -3.4462e-02,  3.9031e-02],\n",
      "          [ 7.7541e-02, -1.5854e-01,  1.0087e-01],\n",
      "          [-1.9987e-01,  3.9211e-02,  1.0430e-01]],\n",
      "\n",
      "         [[-1.4250e-01,  2.2765e-02, -6.7916e-03],\n",
      "          [-1.7132e-01,  1.8668e-01,  6.2170e-02],\n",
      "          [ 1.6771e-01,  1.4918e-01, -2.6153e-02]],\n",
      "\n",
      "         [[-1.3500e-01,  1.7382e-01,  6.6632e-02],\n",
      "          [-1.9192e-01,  6.1581e-02,  9.9999e-02],\n",
      "          [-1.8889e-01,  6.1994e-02, -1.4435e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2595e-01,  2.5269e-02,  1.9934e-01],\n",
      "          [-1.2419e-01, -1.3583e-01, -7.2848e-02],\n",
      "          [ 1.4775e-02, -1.3090e-01,  7.8648e-02]],\n",
      "\n",
      "         [[ 1.3700e-01, -2.8658e-02, -2.0870e-02],\n",
      "          [-4.7278e-02, -1.2408e-02,  2.1546e-01],\n",
      "          [-1.1948e-01, -3.0173e-03,  2.3325e-01]],\n",
      "\n",
      "         [[-1.1314e-01, -9.0883e-02,  1.8456e-02],\n",
      "          [-1.6291e-01,  4.8757e-02, -1.1043e-01],\n",
      "          [ 3.5056e-02,  2.6586e-03,  2.0378e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1717e-01,  1.7408e-01,  7.9788e-02],\n",
      "          [ 8.7160e-02, -1.4874e-01, -1.5103e-01],\n",
      "          [ 1.9060e-01,  9.5981e-02, -1.9405e-02]],\n",
      "\n",
      "         [[ 1.5681e-02, -2.0265e-01,  5.4118e-02],\n",
      "          [ 1.0285e-01, -7.3159e-02, -1.1211e-01],\n",
      "          [ 1.8939e-01, -1.1255e-01, -1.8772e-01]],\n",
      "\n",
      "         [[-1.6636e-01,  1.2162e-01,  3.1709e-02],\n",
      "          [ 1.2054e-01,  7.4812e-02,  1.0899e-01],\n",
      "          [-3.3600e-02,  2.1505e-02,  2.6525e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0888e-01, -9.2189e-02,  1.0189e-01],\n",
      "          [ 1.2948e-01,  2.3186e-02, -2.5035e-02],\n",
      "          [-1.5042e-01,  1.5455e-01, -1.4937e-01]],\n",
      "\n",
      "         [[ 1.4732e-01, -2.2499e-02, -5.9607e-02],\n",
      "          [-7.0852e-02,  3.0651e-02, -1.1186e-02],\n",
      "          [ 3.6315e-02,  1.5829e-01, -2.6283e-02]],\n",
      "\n",
      "         [[ 1.4200e-01, -1.0296e-01,  1.7661e-01],\n",
      "          [ 1.1762e-01, -5.0923e-02,  1.0588e-01],\n",
      "          [-7.7194e-02, -1.0497e-01,  1.2303e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8467e-01,  1.0155e-01, -2.5727e-02],\n",
      "          [ 5.1777e-02,  1.1060e-01, -1.4446e-01],\n",
      "          [-8.8362e-02,  1.2111e-01, -1.8021e-01]],\n",
      "\n",
      "         [[ 1.1937e-01,  1.6317e-01,  2.4986e-02],\n",
      "          [ 1.3361e-01, -6.9380e-02, -1.0360e-01],\n",
      "          [ 2.5015e-02,  1.0282e-01, -1.4180e-01]],\n",
      "\n",
      "         [[-7.9085e-02,  1.1294e-01, -1.1397e-01],\n",
      "          [ 6.7039e-02,  1.9438e-01,  9.7382e-02],\n",
      "          [ 3.0561e-03, -1.2737e-01,  1.7629e-01]]]], requires_grad=True)\n",
      "\n",
      "Dequantize\n",
      "tensor([[[[-0.1643,  0.2190, -0.0162],\n",
      "          [-0.0183,  0.0872,  0.0020],\n",
      "          [-0.0771,  0.0223, -0.0264]],\n",
      "\n",
      "         [[-0.0446, -0.0527, -0.1683],\n",
      "          [-0.0223, -0.1764, -0.1156],\n",
      "          [ 0.1014,  0.0527, -0.0811]],\n",
      "\n",
      "         [[-0.1663,  0.1926, -0.0284],\n",
      "          [-0.1784,  0.1724, -0.1561],\n",
      "          [-0.0892,  0.0933,  0.0406]]],\n",
      "\n",
      "\n",
      "        [[[-0.1318,  0.0061,  0.1176],\n",
      "          [ 0.1278, -0.1399,  0.0304],\n",
      "          [ 0.0791, -0.0020,  0.1582]],\n",
      "\n",
      "         [[-0.1521, -0.0081,  0.1257],\n",
      "          [ 0.0730, -0.0426,  0.0831],\n",
      "          [ 0.0264,  0.1075, -0.1359]],\n",
      "\n",
      "         [[ 0.0811,  0.0142,  0.1034],\n",
      "          [ 0.0426, -0.0669,  0.1278],\n",
      "          [ 0.0243, -0.0507,  0.0162]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0243,  0.1541,  0.1987],\n",
      "          [-0.1237, -0.1054, -0.1156],\n",
      "          [-0.0041,  0.0183, -0.0629]],\n",
      "\n",
      "         [[-0.1379, -0.1298,  0.1419],\n",
      "          [ 0.0527, -0.0284,  0.0183],\n",
      "          [ 0.0791,  0.0710,  0.0041]],\n",
      "\n",
      "         [[-0.1541, -0.0669,  0.0507],\n",
      "          [ 0.0811,  0.0142, -0.1156],\n",
      "          [ 0.0791, -0.1582, -0.1724]]],\n",
      "\n",
      "\n",
      "        [[[-0.0892, -0.0183, -0.0487],\n",
      "          [-0.1602, -0.0507,  0.0000],\n",
      "          [-0.1257, -0.1156, -0.0507]],\n",
      "\n",
      "         [[-0.1805,  0.0750,  0.0750],\n",
      "          [ 0.1257,  0.1744,  0.0020],\n",
      "          [-0.0973,  0.1886,  0.1967]],\n",
      "\n",
      "         [[-0.1196,  0.1196, -0.1257],\n",
      "          [-0.0872,  0.1054,  0.0487],\n",
      "          [ 0.0669,  0.0750, -0.0973]]],\n",
      "\n",
      "\n",
      "        [[[-0.1561, -0.0953, -0.1399],\n",
      "          [-0.0872,  0.1196,  0.1521],\n",
      "          [-0.0892,  0.0649,  0.1886]],\n",
      "\n",
      "         [[-0.1744, -0.1298, -0.0466],\n",
      "          [-0.1886, -0.1906,  0.1419],\n",
      "          [-0.0142,  0.1399,  0.1054]],\n",
      "\n",
      "         [[ 0.0304,  0.1115,  0.0649],\n",
      "          [ 0.0649,  0.0913,  0.0953],\n",
      "          [ 0.1784, -0.1338, -0.1176]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1663, -0.0365,  0.2068],\n",
      "          [ 0.0203,  0.0487, -0.1379],\n",
      "          [-0.0466, -0.0608, -0.0223]],\n",
      "\n",
      "         [[-0.1359, -0.1440, -0.1845],\n",
      "          [-0.0081,  0.0507, -0.1845],\n",
      "          [-0.0629,  0.1663,  0.0243]],\n",
      "\n",
      "         [[-0.0203,  0.0365,  0.1602],\n",
      "          [ 0.1622,  0.0446, -0.0973],\n",
      "          [ 0.0345, -0.0081, -0.0669]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0466, -0.2028, -0.0223],\n",
      "          [ 0.0973,  0.1359,  0.0446],\n",
      "          [ 0.1176,  0.1237,  0.0771]],\n",
      "\n",
      "         [[ 0.1602,  0.0588, -0.0527],\n",
      "          [ 0.1196,  0.0548, -0.0426],\n",
      "          [-0.0913,  0.1480,  0.1906]],\n",
      "\n",
      "         [[-0.1561,  0.0852, -0.1379],\n",
      "          [-0.1460, -0.1987, -0.0750],\n",
      "          [-0.0223,  0.0122, -0.0953]]],\n",
      "\n",
      "\n",
      "        [[[-0.0831, -0.1237, -0.1075],\n",
      "          [-0.1582, -0.0568, -0.0264],\n",
      "          [-0.1054, -0.0689,  0.1724]],\n",
      "\n",
      "         [[ 0.0791,  0.0771,  0.2068],\n",
      "          [ 0.1379,  0.0771,  0.0406],\n",
      "          [ 0.1784, -0.1379,  0.0527]],\n",
      "\n",
      "         [[ 0.0892, -0.0730, -0.0629],\n",
      "          [ 0.0426, -0.0831,  0.1095],\n",
      "          [-0.1582, -0.0913, -0.1176]]],\n",
      "\n",
      "\n",
      "        [[[-0.0304, -0.0223,  0.2271],\n",
      "          [-0.0264,  0.1359,  0.1460],\n",
      "          [ 0.0041, -0.1196, -0.0872]],\n",
      "\n",
      "         [[ 0.1460, -0.0223, -0.0710],\n",
      "          [-0.0588, -0.0507,  0.0811],\n",
      "          [-0.1703, -0.2596, -0.1866]],\n",
      "\n",
      "         [[ 0.2048, -0.0771,  0.1419],\n",
      "          [ 0.1399,  0.0243, -0.1156],\n",
      "          [ 0.0608,  0.0385, -0.1582]]],\n",
      "\n",
      "\n",
      "        [[[-0.1643,  0.0933, -0.0304],\n",
      "          [-0.0365,  0.2109,  0.0020],\n",
      "          [ 0.1582,  0.1521,  0.2008]],\n",
      "\n",
      "         [[-0.1156, -0.1622, -0.0588],\n",
      "          [-0.1582, -0.0689,  0.0162],\n",
      "          [-0.1501, -0.1196,  0.0324]],\n",
      "\n",
      "         [[-0.0994, -0.0852,  0.1967],\n",
      "          [ 0.1926,  0.0426,  0.1480],\n",
      "          [-0.1460,  0.2008, -0.1298]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1075, -0.1419,  0.1541],\n",
      "          [ 0.1217,  0.0791, -0.0892],\n",
      "          [-0.0831, -0.1095,  0.0588]],\n",
      "\n",
      "         [[-0.1379,  0.0264,  0.1237],\n",
      "          [-0.0710,  0.1764,  0.1136],\n",
      "          [-0.1136,  0.0466, -0.1582]],\n",
      "\n",
      "         [[ 0.0284, -0.1034,  0.0345],\n",
      "          [ 0.1176,  0.1926,  0.0831],\n",
      "          [-0.2089,  0.1764, -0.0243]]],\n",
      "\n",
      "\n",
      "        [[[-0.1257,  0.1744,  0.0629],\n",
      "          [ 0.0162,  0.1460, -0.0669],\n",
      "          [-0.1338,  0.0608,  0.0406]],\n",
      "\n",
      "         [[ 0.0852, -0.0020, -0.1115],\n",
      "          [-0.0507,  0.0771, -0.1764],\n",
      "          [ 0.1318, -0.0629, -0.1034]],\n",
      "\n",
      "         [[-0.0142, -0.0365, -0.0324],\n",
      "          [-0.1156,  0.1278,  0.1501],\n",
      "          [ 0.0345,  0.1561, -0.0487]]],\n",
      "\n",
      "\n",
      "        [[[-0.1643, -0.0385, -0.1622],\n",
      "          [ 0.1947,  0.1886, -0.0527],\n",
      "          [-0.1115,  0.0000,  0.1440]],\n",
      "\n",
      "         [[-0.0406,  0.1095,  0.1419],\n",
      "          [-0.0548, -0.0791, -0.0710],\n",
      "          [-0.0507, -0.1196, -0.1278]],\n",
      "\n",
      "         [[-0.1014, -0.0689,  0.0304],\n",
      "          [ 0.1703,  0.0345, -0.1278],\n",
      "          [-0.0669, -0.0162,  0.0994]]],\n",
      "\n",
      "\n",
      "        [[[-0.0162, -0.1176,  0.1703],\n",
      "          [ 0.0162,  0.1501, -0.0223],\n",
      "          [-0.1034, -0.0041,  0.1379]],\n",
      "\n",
      "         [[-0.1886, -0.1075, -0.1906],\n",
      "          [-0.0507, -0.0406,  0.0081],\n",
      "          [ 0.0831, -0.1156, -0.0041]],\n",
      "\n",
      "         [[ 0.1318,  0.0629, -0.1521],\n",
      "          [ 0.1663,  0.0487,  0.1460],\n",
      "          [-0.0223, -0.1399,  0.1419]]],\n",
      "\n",
      "\n",
      "        [[[-0.1136, -0.0771,  0.1298],\n",
      "          [-0.2170,  0.0994,  0.1095],\n",
      "          [-0.1298, -0.0730, -0.0466]],\n",
      "\n",
      "         [[-0.1561, -0.0203, -0.0324],\n",
      "          [ 0.0122,  0.0811,  0.0852],\n",
      "          [-0.1926,  0.0466, -0.1379]],\n",
      "\n",
      "         [[ 0.0162,  0.1298, -0.0385],\n",
      "          [-0.0669,  0.0933,  0.1278],\n",
      "          [ 0.1764,  0.1724,  0.1744]]],\n",
      "\n",
      "\n",
      "        [[[-0.0385,  0.1136,  0.0811],\n",
      "          [-0.1014, -0.0345,  0.0771],\n",
      "          [-0.1663,  0.0669,  0.0487]],\n",
      "\n",
      "         [[-0.0142,  0.1825, -0.0973],\n",
      "          [ 0.1582, -0.1541, -0.0649],\n",
      "          [ 0.0527,  0.1480,  0.0994]],\n",
      "\n",
      "         [[ 0.0771,  0.1744, -0.0791],\n",
      "          [-0.0548, -0.0406, -0.1582],\n",
      "          [-0.1825,  0.0061, -0.0466]]],\n",
      "\n",
      "\n",
      "        [[[-0.1095, -0.1379, -0.0791],\n",
      "          [-0.1480, -0.1541,  0.0466],\n",
      "          [-0.0811,  0.0426, -0.1480]],\n",
      "\n",
      "         [[ 0.0304,  0.0304, -0.0791],\n",
      "          [ 0.1643, -0.1318, -0.0183],\n",
      "          [ 0.0385,  0.1480, -0.1359]],\n",
      "\n",
      "         [[-0.0101, -0.0081,  0.1501],\n",
      "          [ 0.0791, -0.0730,  0.1318],\n",
      "          [-0.0243, -0.0264,  0.1156]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0041, -0.0750, -0.0324],\n",
      "          [ 0.0791,  0.0689, -0.0243],\n",
      "          [ 0.0284, -0.0284, -0.0426]],\n",
      "\n",
      "         [[ 0.1805,  0.0122, -0.2332],\n",
      "          [ 0.0142,  0.0852,  0.0953],\n",
      "          [ 0.1379, -0.1379, -0.0162]],\n",
      "\n",
      "         [[ 0.1217, -0.0994, -0.1784],\n",
      "          [ 0.1217,  0.0994, -0.1866],\n",
      "          [ 0.0872,  0.0061, -0.1764]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0689,  0.0101,  0.0588],\n",
      "          [-0.1156,  0.1643,  0.1541],\n",
      "          [-0.0973,  0.1176, -0.0771]],\n",
      "\n",
      "         [[ 0.1663, -0.0304, -0.1257],\n",
      "          [ 0.1237, -0.0913, -0.0608],\n",
      "          [-0.1419,  0.1054, -0.1196]],\n",
      "\n",
      "         [[-0.1399, -0.0041, -0.0365],\n",
      "          [ 0.0101, -0.1602,  0.1744],\n",
      "          [-0.0122,  0.0933, -0.0892]]],\n",
      "\n",
      "\n",
      "        [[[-0.0020, -0.1501,  0.1784],\n",
      "          [ 0.1095, -0.1257,  0.0689],\n",
      "          [ 0.1501,  0.0953, -0.0710]],\n",
      "\n",
      "         [[-0.1582,  0.0122,  0.0973],\n",
      "          [-0.1318,  0.0953, -0.0284],\n",
      "          [-0.0548, -0.1561,  0.0953]],\n",
      "\n",
      "         [[-0.1541, -0.1643, -0.1115],\n",
      "          [-0.0913, -0.1582,  0.0243],\n",
      "          [-0.0203,  0.1014, -0.1643]]],\n",
      "\n",
      "\n",
      "        [[[-0.0771, -0.0568,  0.1541],\n",
      "          [ 0.1115,  0.0994,  0.1196],\n",
      "          [ 0.0142,  0.0568,  0.0122]],\n",
      "\n",
      "         [[-0.1379, -0.0101,  0.1582],\n",
      "          [-0.2068, -0.1440, -0.0994],\n",
      "          [-0.1237,  0.0933, -0.1054]],\n",
      "\n",
      "         [[ 0.0446, -0.0669,  0.0689],\n",
      "          [ 0.0466, -0.1602, -0.0020],\n",
      "          [ 0.0913,  0.0000, -0.0183]]],\n",
      "\n",
      "\n",
      "        [[[-0.1501,  0.0466,  0.1054],\n",
      "          [ 0.1014, -0.1217, -0.1278],\n",
      "          [ 0.0791,  0.0791, -0.1906]],\n",
      "\n",
      "         [[-0.0365, -0.1947,  0.1217],\n",
      "          [-0.1460,  0.0020, -0.1217],\n",
      "          [-0.1480, -0.1095,  0.0426]],\n",
      "\n",
      "         [[ 0.0223, -0.1156,  0.1034],\n",
      "          [ 0.1115,  0.1602,  0.1075],\n",
      "          [ 0.0061,  0.0953,  0.0183]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1703, -0.0568, -0.0791],\n",
      "          [ 0.1501,  0.0913, -0.0284],\n",
      "          [-0.0466, -0.0994, -0.0101]],\n",
      "\n",
      "         [[ 0.1196,  0.0548,  0.1866],\n",
      "          [-0.1663, -0.1460, -0.0568],\n",
      "          [-0.1683, -0.1054,  0.0669]],\n",
      "\n",
      "         [[-0.0548,  0.1764,  0.1561],\n",
      "          [ 0.1906,  0.1298,  0.1825],\n",
      "          [ 0.1866, -0.0811,  0.0487]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1987,  0.1318, -0.1095],\n",
      "          [ 0.0142, -0.0548, -0.1440],\n",
      "          [-0.0568,  0.1866, -0.1683]],\n",
      "\n",
      "         [[-0.0142, -0.0811, -0.1501],\n",
      "          [-0.1866, -0.1095, -0.1947],\n",
      "          [ 0.1034,  0.1784, -0.1967]],\n",
      "\n",
      "         [[-0.1440, -0.1136, -0.0101],\n",
      "          [ 0.1095,  0.0608,  0.0446],\n",
      "          [ 0.2008,  0.0020,  0.1926]]],\n",
      "\n",
      "\n",
      "        [[[-0.1602,  0.0243,  0.0426],\n",
      "          [-0.0913, -0.0223,  0.0406],\n",
      "          [ 0.1602, -0.1582,  0.1217]],\n",
      "\n",
      "         [[-0.1014,  0.1217,  0.1115],\n",
      "          [-0.1643,  0.1784,  0.2312],\n",
      "          [-0.1298, -0.1298,  0.0669]],\n",
      "\n",
      "         [[-0.0101, -0.0081, -0.0264],\n",
      "          [-0.1338,  0.0142, -0.0426],\n",
      "          [-0.0730,  0.1298, -0.0101]]],\n",
      "\n",
      "\n",
      "        [[[-0.1460,  0.0892,  0.0243],\n",
      "          [ 0.0020, -0.0608,  0.1845],\n",
      "          [-0.1663,  0.0933, -0.0689]],\n",
      "\n",
      "         [[-0.0730, -0.1419,  0.1217],\n",
      "          [-0.0020, -0.1034, -0.0548],\n",
      "          [-0.1480,  0.1176,  0.1237]],\n",
      "\n",
      "         [[ 0.1866,  0.0548,  0.0000],\n",
      "          [-0.1095, -0.0913, -0.1338],\n",
      "          [-0.0811,  0.0041,  0.0568]]],\n",
      "\n",
      "\n",
      "        [[[-0.0101,  0.0649, -0.1379],\n",
      "          [-0.0568, -0.0426, -0.1622],\n",
      "          [-0.1683, -0.0892,  0.0994]],\n",
      "\n",
      "         [[ 0.1054,  0.1683,  0.0710],\n",
      "          [ 0.0872, -0.1034,  0.0345],\n",
      "          [ 0.1561,  0.1338,  0.0041]],\n",
      "\n",
      "         [[-0.0527, -0.0507,  0.1115],\n",
      "          [-0.2251, -0.0243, -0.0507],\n",
      "          [ 0.1278, -0.1825, -0.0527]]],\n",
      "\n",
      "\n",
      "        [[[-0.0406, -0.0345,  0.0385],\n",
      "          [ 0.0771, -0.1582,  0.1014],\n",
      "          [-0.2008,  0.0385,  0.1034]],\n",
      "\n",
      "         [[-0.1419,  0.0223, -0.0061],\n",
      "          [-0.1703,  0.1866,  0.0629],\n",
      "          [ 0.1683,  0.1501, -0.0264]],\n",
      "\n",
      "         [[-0.1359,  0.1744,  0.0669],\n",
      "          [-0.1926,  0.0608,  0.0994],\n",
      "          [-0.1886,  0.0629, -0.1440]]],\n",
      "\n",
      "\n",
      "        [[[-0.1257,  0.0243,  0.1987],\n",
      "          [-0.1237, -0.1359, -0.0730],\n",
      "          [ 0.0142, -0.1318,  0.0791]],\n",
      "\n",
      "         [[ 0.1379, -0.0284, -0.0203],\n",
      "          [-0.0466, -0.0122,  0.2149],\n",
      "          [-0.1196, -0.0020,  0.2332]],\n",
      "\n",
      "         [[-0.1136, -0.0913,  0.0183],\n",
      "          [-0.1622,  0.0487, -0.1095],\n",
      "          [ 0.0345,  0.0020,  0.2028]]],\n",
      "\n",
      "\n",
      "        [[[-0.1176,  0.1744,  0.0791],\n",
      "          [ 0.0872, -0.1480, -0.1501],\n",
      "          [ 0.1906,  0.0953, -0.0203]],\n",
      "\n",
      "         [[ 0.0162, -0.2028,  0.0548],\n",
      "          [ 0.1034, -0.0730, -0.1115],\n",
      "          [ 0.1886, -0.1136, -0.1886]],\n",
      "\n",
      "         [[-0.1663,  0.1217,  0.0324],\n",
      "          [ 0.1196,  0.0750,  0.1095],\n",
      "          [-0.0345,  0.0223,  0.0264]]],\n",
      "\n",
      "\n",
      "        [[[-0.1095, -0.0913,  0.1014],\n",
      "          [ 0.1298,  0.0223, -0.0243],\n",
      "          [-0.1501,  0.1541, -0.1501]],\n",
      "\n",
      "         [[ 0.1480, -0.0223, -0.0588],\n",
      "          [-0.0710,  0.0304, -0.0122],\n",
      "          [ 0.0365,  0.1582, -0.0264]],\n",
      "\n",
      "         [[ 0.1419, -0.1034,  0.1764],\n",
      "          [ 0.1176, -0.0507,  0.1054],\n",
      "          [-0.0771, -0.1054,  0.1237]]],\n",
      "\n",
      "\n",
      "        [[[-0.1845,  0.1014, -0.0264],\n",
      "          [ 0.0527,  0.1115, -0.1440],\n",
      "          [-0.0892,  0.1217, -0.1805]],\n",
      "\n",
      "         [[ 0.1196,  0.1622,  0.0243],\n",
      "          [ 0.1338, -0.0689, -0.1034],\n",
      "          [ 0.0243,  0.1034, -0.1419]],\n",
      "\n",
      "         [[-0.0791,  0.1136, -0.1136],\n",
      "          [ 0.0669,  0.1947,  0.0973],\n",
      "          [ 0.0041, -0.1278,  0.1764]]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare Weights\n",
    "print('Original')\n",
    "print(net.conv1.weight)\n",
    "print('')\n",
    "print(f'Dequantize')\n",
    "print(torch.dequantize(net_quant.conv1.weight()))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "037c76ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after quantization\n",
      "Size(KB): 456.117\n"
     ]
    }
   ],
   "source": [
    "print(\"Size after quantization\")\n",
    "print_size_of_model(net_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "06508721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing after quantization\n",
      "Precisión total: 73.91%\n"
     ]
    }
   ],
   "source": [
    "print('Testing after quantization')\n",
    "test(net_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea613d5",
   "metadata": {},
   "source": [
    "Brevita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb5fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import brevitas.nn as qnn\n",
    "from brevitas import Int8WeightPerTensorFloat\n",
    "\n",
    "class QuantTinyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuantTinyCNN,self).__init__()\n",
    "        quantinfo = {'weight_quant': Int8WeightPerTensorFloat, 'weight_bit_width': 8 }\n",
    "\n",
    "        self.conv1 = qnn.QuantConv2d(3,32,kernel_size=3,padding=1,**quantinfo)\n",
    "        self.relu1 = qnn.QuantReLU(bit_width = 8)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = qnn.QuantConv2d(32, 64, kernel_size=3, padding=1, **quantinfo)\n",
    "        self.relu2 = qnn.QuantReLU(bit_width=8)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = qnn.QuantConv2d(64, 128, kernel_size=3, padding=1, **quantinfo)\n",
    "        self.relu3 = qnn.QuantReLU(bit_width=8)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv4 = qnn.QuantConv2d(128, 128, kernel_size=3, padding=1, **quantinfo)\n",
    "        self.relu4 = qnn.QuantReLU(bit_width=8)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = qnn.QuantLinear(128*4*4,100,**quantinfo)\n",
    "        self.relu_fc1 = qnn.QuantReLU(bit_width = 8)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = qnn.QuantLinear(100,2,**quantinfo)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.pool3(self.relu3(self.conv3(x)))\n",
    "        x = self.pool4(self.relu4(self.conv4(x)))\n",
    "        \n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.relu_fc1(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
