{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "60491b51-babd-4b8f-938d-51ccdf767a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/finn_dev_parasyte\n"
     ]
    }
   ],
   "source": [
    "user_name = \"parasyte\" # REPLACE THIS WITH YOUR HOST MACHINE USER NAME \n",
    "root_dir = f\"/tmp/finn_dev_{user_name}\"\n",
    "print(root_dir)\n",
    "# get onnx model from the last NOTEBOOK\n",
    "filename = root_dir + \"/ready_finn.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "17b4cbe8-7d00-48c4-bac7-8717a3f1fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.visualization import showSrc, showInNetron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c0ce7189-7722-4cad-ba4b-91e204be6fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "384acc5f-5fac-42b1-8e71-06e69d709516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class InferShapes(Transformation):\n",
      "    \"\"\"Ensure every tensor in the model has a specified shape (ValueInfo).\"\"\"\n",
      "\n",
      "    def apply(self, model):\n",
      "        # hide your riches!\n",
      "        hidden_ops = _hide_finn_ops(model)\n",
      "        # call regular ONNX shape inference\n",
      "        model = ModelWrapper(si.infer_shapes(model.model))\n",
      "        # bring back hidden ops\n",
      "        _restore_finn_ops(model, hidden_ops)\n",
      "        return (model, False)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "\n",
    "model = ModelWrapper(filename)\n",
    "\n",
    "# TIDY UP\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "\n",
    "model.save(root_dir + \"/tidy.onnx\")\n",
    "\n",
    "showSrc(InferShapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d2ee3e35-2ae5-4ed2-913b-82585f6af619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(root_dir + \"/tidy.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8001b773-ab70-43ec-a2cf-3bdb90572dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from finn.util.pytorch import ToTensor\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "from qonnx.core.datatype import DataType\n",
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "import torch\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "\n",
    "# PRE PROC : NONE\n",
    "model = ModelWrapper(root_dir + \"/tidy.onnx\")\n",
    "\n",
    "#=========================================================\n",
    "# Here you could add some proprocessing if you need some\n",
    "#=========================================================\n",
    "\n",
    "# add input annotation: UINT8 is what we will feed the model during inference\n",
    "global_inp_name = model.graph.input[0].name\n",
    "model.set_tensor_datatype(global_inp_name, DataType[\"UINT8\"])\n",
    "\n",
    "\n",
    "model.save(root_dir + \"/full_preproc.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "deb5f8cd-eb9c-4820-a2c1-53d12b58d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(root_dir + \"/full_preproc.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b09bd025-7bfb-428e-af47-c73be958bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from qonnx.transformation.insert_topk import InsertTopK\n",
    "\n",
    "# POST PROC\n",
    "\n",
    "# insert Top-1 node at the end\n",
    "model = model.transform(InsertTopK(k=1))\n",
    "chkpt_name = root_dir + \"/pre_post.onnx\"\n",
    "# tidy-up again\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "model.save(chkpt_name)\n",
    "\n",
    "# showInNetron(chkpt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b4822010-2f2f-4d7d-94cf-ba897eafc904",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from finn.transformation.streamline import Streamline\n",
    "# we can see the list of apllied transformations here : showSrc(Streamline)\n",
    "from finn.transformation.streamline.reorder import MoveScalarLinearPastInvariants\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "\n",
    "model = ModelWrapper(root_dir + \"/pre_post.onnx\")\n",
    "# STREAMLINE\n",
    "model = model.transform(Streamline())\n",
    "model.save(root_dir + \"/streamlined.onnx\")\n",
    "# showInNetron(root_dir + \"/streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7c610224-eded-4ad2-b7f9-dd49c3a2668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.streamline.round_thresholds import RoundAndClipThresholds\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.general import RemoveUnusedTensors\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "\n",
    "model = ModelWrapper(root_dir + \"/streamlined.onnx\")\n",
    "\n",
    "# absorb final add-mul nodes into TopK\n",
    "model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "model = model.transform(RoundAndClipThresholds())\n",
    "\n",
    "# bit of tidy-up\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "\n",
    "model.save(root_dir + \"/streamlined_merged_and_ready.onnx\")\n",
    "# showInNetron(root_dir + \"/streamlined_merged_and_ready.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a2a3b0c4-6592-4cc4-83e1-069c98033923",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serving '/tmp/finn_dev_parasyte/hw.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7faace7e0d90>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "\n",
    "# TO HW LAYERS\n",
    "\n",
    "model = ModelWrapper(root_dir + \"/streamlined_merged_and_ready.onnx\")\n",
    "model = model.transform(to_hw.InferLabelSelectLayer())\n",
    "model = model.transform(to_hw.InferChannelwiseLinearLayer())\n",
    "model = model.transform(to_hw.InferQuantizedMatrixVectorActivation())\n",
    "model = model.transform(to_hw.InferThresholdingLayer())\n",
    "model.save(root_dir + \"/hw.onnx\")\n",
    "showInNetron(root_dir + \"/hw.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5877c229-23ed-43f5-931e-b634fa5ab35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de nodos encontrados en hw.onnx:\n",
      " {'Add', 'MVAU', 'Mul', 'Reshape', 'TopK', 'Thresholding', 'Conv', 'MaxPool', 'Transpose'}\n"
     ]
    }
   ],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "\n",
    "hw_model = ModelWrapper(root_dir + \"/hw.onnx\")\n",
    "\n",
    "# listar todos los tipos de nodos que contiene\n",
    "op_types = set([n.op_type for n in hw_model.graph.node])\n",
    "print(\"Tipos de nodos encontrados en hw.onnx:\\n\", op_types)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c0893de0-54de-401b-ae37-307f8240a425",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "cycle-free graph violated: partition depends on itself",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfinn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfpgadataflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcreate_dataflow_partition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CreateDataflowPartition\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m ModelWrapper(root_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/hw.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m parent_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCreateDataflowPartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m parent_model\u001b[38;5;241m.\u001b[39msave(root_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/df_part.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m showInNetron(root_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/df_part.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/parasyte/finn/deps/qonnx/src/qonnx/core/modelwrapper.py:140\u001b[0m, in \u001b[0;36mModelWrapper.transform\u001b[0;34m(self, transformation, make_deepcopy, cleanup)\u001b[0m\n\u001b[1;32m    138\u001b[0m model_was_changed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m model_was_changed:\n\u001b[0;32m--> 140\u001b[0m     (transformed_model, model_was_changed) \u001b[38;5;241m=\u001b[39m \u001b[43mtransformation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n\u001b[1;32m    142\u001b[0m     transformed_model\u001b[38;5;241m.\u001b[39mcleanup()\n",
      "File \u001b[0;32m/home/parasyte/finn/src/finn/transformation/fpgadataflow/create_dataflow_partition.py:80\u001b[0m, in \u001b[0;36mCreateDataflowPartition.apply\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# first, use the generic partitioning functionality to split up the graph\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m parent_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPartitionFromLambda\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43massign_partition_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartition_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartition_model_dir\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# change node types to StreamingDataflowPartition\u001b[39;00m\n\u001b[1;32m     86\u001b[0m p_nodes \u001b[38;5;241m=\u001b[39m parent_model\u001b[38;5;241m.\u001b[39mget_nodes_by_op_type(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenericPartition\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/parasyte/finn/deps/qonnx/src/qonnx/core/modelwrapper.py:140\u001b[0m, in \u001b[0;36mModelWrapper.transform\u001b[0;34m(self, transformation, make_deepcopy, cleanup)\u001b[0m\n\u001b[1;32m    138\u001b[0m model_was_changed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m model_was_changed:\n\u001b[0;32m--> 140\u001b[0m     (transformed_model, model_was_changed) \u001b[38;5;241m=\u001b[39m \u001b[43mtransformation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n\u001b[1;32m    142\u001b[0m     transformed_model\u001b[38;5;241m.\u001b[39mcleanup()\n",
      "File \u001b[0;32m/home/parasyte/finn/deps/qonnx/src/qonnx/transformation/create_generic_partitions.py:119\u001b[0m, in \u001b[0;36mPartitionFromLambda.apply\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m to_check:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m--> 119\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitioning(node) \u001b[38;5;241m!=\u001b[39m partition_id\n\u001b[1;32m    120\u001b[0m         ), \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mcycle-free graph violated: partition depends on itself\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;66;03m# print(node)\u001b[39;00m\n\u001b[1;32m    122\u001b[0m         predecessors \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfind_direct_predecessors(node)\n",
      "\u001b[0;31mAssertionError\u001b[0m: cycle-free graph violated: partition depends on itself"
     ]
    }
   ],
   "source": [
    "from finn.transformation.fpgadataflow.create_dataflow_partition import CreateDataflowPartition\n",
    "\n",
    "model = ModelWrapper(root_dir + \"/hw.onnx\")\n",
    "parent_model = model.transform(CreateDataflowPartition())\n",
    "parent_model.save(root_dir + \"/df_part.onnx\")\n",
    "showInNetron(root_dir + \"/df_part.onnx\")\n",
    "\n",
    "# We see that our entire model is now part of a child model in \"StreamingDataflowPartition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7ad12209-d568-4dfc-aae7-a9ff5c8dc22a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parent_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mqonnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcustom_op\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m getCustomOp\n\u001b[0;32m----> 2\u001b[0m sdp_node \u001b[38;5;241m=\u001b[39m \u001b[43mparent_model\u001b[49m\u001b[38;5;241m.\u001b[39mget_nodes_by_op_type(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStreamingDataflowPartition\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m sdp_node \u001b[38;5;241m=\u001b[39m getCustomOp(sdp_node)\n\u001b[1;32m      4\u001b[0m dataflow_model_filename \u001b[38;5;241m=\u001b[39m sdp_node\u001b[38;5;241m.\u001b[39mget_nodeattr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parent_model' is not defined"
     ]
    }
   ],
   "source": [
    "from qonnx.custom_op.registry import getCustomOp\n",
    "sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "sdp_node = getCustomOp(sdp_node)\n",
    "dataflow_model_filename = sdp_node.get_nodeattr(\"model\")\n",
    "showInNetron(dataflow_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9ccd06f3-37fc-4316-81e1-27d0dda480be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Ultra96', 'Ultra96-V2', 'Pynq-Z1', 'Pynq-Z2', 'ZCU102', 'ZCU104', 'ZCU111', 'RFSoC2x2', 'RFSoC4x2', 'KV260_SOM'])\n"
     ]
    }
   ],
   "source": [
    "# print the names of the supported PYNQ boards\n",
    "from finn.util.basic import pynq_part_map\n",
    "print(pynq_part_map.keys())\n",
    "\n",
    "# change this if you have a different PYNQ board, see list above\n",
    "pynq_board = \"Pynq-Z2\"\n",
    "fpga_part = pynq_part_map[pynq_board]\n",
    "target_clk_ns = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "99855ce7-b704-4660-aabc-3fdaab8baa3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataflow_model_filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfinn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfpgadataflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecialize_layers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SpecializeLayers\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m ModelWrapper(\u001b[43mdataflow_model_filename\u001b[49m)\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtransform(SpecializeLayers(fpga_part))\n\u001b[1;32m      6\u001b[0m showSrc(SpecializeLayers)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataflow_model_filename' is not defined"
     ]
    }
   ],
   "source": [
    "from finn.transformation.fpgadataflow.specialize_layers import SpecializeLayers\n",
    "model = ModelWrapper(dataflow_model_filename)\n",
    "\n",
    "model = model.transform(SpecializeLayers(fpga_part))\n",
    "\n",
    "showSrc(SpecializeLayers)\n",
    "\n",
    "model.save(root_dir + \"/to_hw_conv.onnx\")\n",
    "showInNetron(root_dir + \"/to_hw_conv.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
